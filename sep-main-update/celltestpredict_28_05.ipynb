{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.5.0\n",
      "  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch==2.5.0)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (4.13.2)\n",
      "Collecting networkx (from torch==2.5.0)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.5.0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.5.0)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.0)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.0)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.0)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m144.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torch]m20/21\u001b[0m [torch]-cusolver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.0 triton-3.1.0\n",
      "Collecting numpy==2.2.6\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n",
      "Collecting openai==1.79.0\n",
      "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/.venv/lib/python3.10/site-packages (from openai==1.79.0) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.79.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/.venv/lib/python3.10/site-packages (from openai==1.79.0) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.79.0)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/.venv/lib/python3.10/site-packages (from openai==1.79.0) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /root/.venv/lib/python3.10/site-packages (from openai==1.79.0) (1.3.1)\n",
      "Collecting tqdm>4 (from openai==1.79.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/.venv/lib/python3.10/site-packages (from openai==1.79.0) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.79.0) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.79.0) (3.10)\n",
      "Requirement already satisfied: certifi in /root/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.79.0) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /root/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.79.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /root/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.79.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.79.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.79.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.79.0) (0.4.1)\n",
      "Downloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [openai]2m3/4\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.10.0 openai-1.79.0 tqdm-4.67.1\n",
      "Collecting tenacity==9.1.2\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-9.1.2\n",
      "Collecting tiktoken==0.9.0\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.9.0)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken==0.9.0)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken==0.9.0)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.9.0) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken==0.9.0)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.9.0) (2025.4.26)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, regex, charset-normalizer, requests, tiktoken\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [tiktoken]3/5\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed charset-normalizer-3.4.2 regex-2024.11.6 requests-2.32.3 tiktoken-0.9.0 urllib3-2.4.0\n",
      "Collecting transformers==4.51.3\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.51.3)\n",
      "  Downloading huggingface_hub-0.32.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.51.3)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.51.3)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/.venv/lib/python3.10/site-packages (from transformers==4.51.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.13.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.venv/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests->transformers==4.51.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests->transformers==4.51.3) (2025.4.26)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, pyyaml, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.2 huggingface-hub-0.32.2 pyyaml-6.0.2 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n",
      "Collecting pandas==2.2.3\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/.venv/lib/python3.10/site-packages (from pandas==2.2.3) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.venv/lib/python3.10/site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.3)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.3)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Collecting scikit-learn==1.6.1\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /root/.venv/lib/python3.10/site-packages (from scikit-learn==1.6.1) (2.2.6)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.6.1)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.6.1)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Collecting bitsandbytes==0.45.5\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /root/.venv/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (2.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.venv/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (2.2.6)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (4.13.2)\n",
      "Requirement already satisfied: networkx in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/.venv/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes==0.45.5) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes==0.45.5) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n",
      "Collecting datasets==3.6.0\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (2.2.6)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.6.0)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.6.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (4.67.1)\n",
      "Collecting xxhash (from datasets==3.6.0)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.6.0)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (0.32.2)\n",
      "Requirement already satisfied: packaging in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/.venv/lib/python3.10/site-packages (from datasets==3.6.0) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiohttp-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /root/.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /root/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets==3.6.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/14\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/14\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/14\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/14\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [datasets]/14\u001b[0m [datasets]t]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.2 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.0\n",
      "Collecting sentencepiece==0.2.0\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Collecting peft==0.15.2\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (25.0)\n",
      "Requirement already satisfied: psutil in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (2.5.0)\n",
      "Requirement already satisfied: transformers in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.15.2)\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/.venv/lib/python3.10/site-packages (from peft==0.15.2) (0.32.2)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2025.3.0)\n",
      "Requirement already satisfied: requests in /root/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (1.1.2)\n",
      "Requirement already satisfied: networkx in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.15.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.15.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (2025.4.26)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.venv/lib/python3.10/site-packages (from transformers->peft==0.15.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/.venv/lib/python3.10/site-packages (from transformers->peft==0.15.2) (0.21.1)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [peft][32m1/2\u001b[0m [peft]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.7.0 peft-0.15.2\n",
      "Collecting evaluate==0.4.3\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (2.2.6)\n",
      "Requirement already satisfied: dill in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /root/.venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.3) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (0.32.2)\n",
      "Requirement already satisfied: packaging in /root/.venv/lib/python3.10/site-packages (from evaluate==0.4.3) (25.0)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.3) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.3) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.3) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/.venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.3) (3.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /root/.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /root/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.3) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.3) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.3) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.venv/lib/python3.10/site-packages (from pandas->evaluate==0.4.3) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.3) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Collecting trl==0.11.4\n",
      "  Downloading trl-0.11.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /root/.venv/lib/python3.10/site-packages (from trl==0.11.4) (2.5.0)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /root/.venv/lib/python3.10/site-packages (from trl==0.11.4) (4.51.3)\n",
      "Requirement already satisfied: accelerate in /root/.venv/lib/python3.10/site-packages (from trl==0.11.4) (1.7.0)\n",
      "Requirement already satisfied: datasets in /root/.venv/lib/python3.10/site-packages (from trl==0.11.4) (3.6.0)\n",
      "Collecting tyro>=0.5.11 (from trl==0.11.4)\n",
      "  Downloading tyro-0.9.22-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /root/.venv/lib/python3.10/site-packages (from trl==0.11.4) (2.2.6)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (4.13.2)\n",
      "Requirement already satisfied: networkx in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/.venv/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.4) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.11.4) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.32.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/.venv/lib/python3.10/site-packages (from transformers>=4.40.0->trl==0.11.4) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.40.0->trl==0.11.4) (1.1.2)\n",
      "Collecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/.venv/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /root/.venv/lib/python3.10/site-packages (from accelerate->trl==0.11.4) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/.venv/lib/python3.10/site-packages (from datasets->trl==0.11.4) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/.venv/lib/python3.10/site-packages (from datasets->trl==0.11.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/.venv/lib/python3.10/site-packages (from datasets->trl==0.11.4) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /root/.venv/lib/python3.10/site-packages (from datasets->trl==0.11.4) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/.venv/lib/python3.10/site-packages (from datasets->trl==0.11.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/.venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (3.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /root/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.11.4) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl==0.11.4) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.11.4) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets->trl==0.11.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets->trl==0.11.4) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.venv/lib/python3.10/site-packages (from pandas->datasets->trl==0.11.4) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.11.4) (1.17.0)\n",
      "Downloading trl-0.11.4-py3-none-any.whl (316 kB)\n",
      "Downloading tyro-0.9.22-py3-none-any.whl (125 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: typeguard, shtab, mdurl, docstring-parser, markdown-it-py, rich, tyro, trl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [trl]\u001b[32m7/8\u001b[0m [trl]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed docstring-parser-0.16 markdown-it-py-3.0.0 mdurl-0.1.2 rich-14.0.0 shtab-1.7.2 trl-0.11.4 typeguard-4.4.2 tyro-0.9.22\n",
      "Collecting protobuf==6.31.0\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl (320 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-6.31.0\n",
      "Collecting python-dotenv==1.1.0\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Collecting pandas_ta\n",
      "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /root/.venv/lib/python3.10/site-packages (from pandas_ta) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/.venv/lib/python3.10/site-packages (from pandas->pandas_ta) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.venv/lib/python3.10/site-packages (from pandas->pandas_ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.venv/lib/python3.10/site-packages (from pandas->pandas_ta) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.venv/lib/python3.10/site-packages (from pandas->pandas_ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.17.0)\n",
      "Building wheels for collected packages: pandas_ta\n",
      "  Building wheel for pandas_ta (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218984 sha256=05978fc8f56af6ee1f813c00bc0fa349578ed2f7cac2c7cf35a9a7839b857d51\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\n",
      "Successfully built pandas_ta\n",
      "Installing collected packages: pandas_ta\n",
      "Successfully installed pandas_ta-0.3.14b0\n",
      "Requirement already satisfied: ollama==0.4.8 in /root/.venv/lib/python3.10/site-packages (0.4.8)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /root/.venv/lib/python3.10/site-packages (from ollama==0.4.8) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /root/.venv/lib/python3.10/site-packages (from ollama==0.4.8) (2.11.5)\n",
      "Requirement already satisfied: anyio in /root/.venv/lib/python3.10/site-packages (from httpx<0.29,>=0.27->ollama==0.4.8) (4.9.0)\n",
      "Requirement already satisfied: certifi in /root/.venv/lib/python3.10/site-packages (from httpx<0.29,>=0.27->ollama==0.4.8) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /root/.venv/lib/python3.10/site-packages (from httpx<0.29,>=0.27->ollama==0.4.8) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/.venv/lib/python3.10/site-packages (from httpx<0.29,>=0.27->ollama==0.4.8) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /root/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama==0.4.8) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama==0.4.8) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama==0.4.8) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /root/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama==0.4.8) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama==0.4.8) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.venv/lib/python3.10/site-packages (from anyio->httpx<0.29,>=0.27->ollama==0.4.8) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/.venv/lib/python3.10/site-packages (from anyio->httpx<0.29,>=0.27->ollama==0.4.8) (1.3.1)\n",
      "Requirement already satisfied: accelerate==1.7.0 in /root/.venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (25.0)\n",
      "Requirement already satisfied: psutil in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (2.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (0.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/.venv/lib/python3.10/site-packages (from accelerate==1.7.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.3.0)\n",
      "Requirement already satisfied: requests in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (1.1.2)\n",
      "Requirement already satisfied: networkx in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.7.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.4.26)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /root/.venv/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /root/.venv/lib/python3.10/site-packages (from ipywidgets) (8.36.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/.venv/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /root/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: wcwidth in /root/.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /root/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /root/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pynvml==8.1.7 (from versions: 8.0.1, 8.0.2, 8.0.3, 8.0.4, 11.0.0, 11.4.0, 11.4.1, 11.5.0, 11.5.2, 11.5.3, 12.0.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pynvml==8.1.7\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: torch 2.5.0\n",
      "Uninstalling torch-2.5.0:\n",
      "  Successfully uninstalled torch-2.5.0\n",
      "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.5.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp310-cp310-linux_x86_64.whl (908.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.20.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.5.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (4.13.2)\n",
      "Requirement already satisfied: networkx in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/.venv/lib/python3.10/site-packages (from torch==2.5.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in /root/.venv/lib/python3.10/site-packages (from torchvision==0.20.0) (2.2.6)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.20.0)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/.venv/lib/python3.10/site-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torchaudio]4\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pillow-11.0.0 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.5.0\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install openai==1.79.0\n",
    "# !pip install tenacity==9.1.2\n",
    "# !pip install tiktoken==0.9.0\n",
    "# !pip install transformers==4.51.3\n",
    "# !pip install pandas==2.2.3\n",
    "# !pip install scikit-learn==1.6.1\n",
    "# !pip install bitsandbytes==0.45.5\n",
    "# !pip install datasets==3.6.0\n",
    "# !pip install sentencepiece==0.2.0\n",
    "# !pip install peft==0.15.2\n",
    "# !pip install evaluate==0.4.3\n",
    "# !pip install trl==0.11.4\n",
    "# !pip install protobuf==6.31.0\n",
    "# !pip install python-dotenv==1.1.0\n",
    "# !pip install pandas_ta\n",
    "# !pip install ollama==0.4.8\n",
    "# !pip install accelerate==1.7.0\n",
    "# !pip install ipywidgets\n",
    "# !pip install pynvml==8.1.7\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.26.4\n",
      "openai==1.79.0\n",
      "tenacity==9.1.2\n",
      "tiktoken==0.9.0\n",
      "transformers==4.51.3\n",
      "pandas==2.2.3\n",
      "scikit-learn==1.6.1\n",
      "torch==2.5.0+cu124\n",
      "bitsandbytes==0.45.5\n",
      "datasets==3.6.0\n",
      "sentencepiece==0.2.0\n",
      "peft==0.15.2\n",
      "evaluate==0.4.3\n",
      "trl==0.11.4\n",
      "protobuf==6.31.0\n",
      "python-dotenv==1.1.0\n",
      "pandas_ta==0.3.14b0\n",
      "ollama==0.4.8\n",
      "accelerate==1.7.0\n",
      "ipywidgets==8.1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5990/316775683.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "libs = [\n",
    "    \"numpy\", \"openai\", \"tenacity\", \"tiktoken\", \"transformers\", \"pandas\",\n",
    "    \"scikit-learn\", \"torch\", \"bitsandbytes\", \"datasets\", \"sentencepiece\",\n",
    "    \"peft\", \"evaluate\", \"trl\", \"protobuf\", \"python-dotenv\", \"pandas_ta\",\n",
    "    \"ollama\", \"accelerate\", \"ipywidgets\"\n",
    "]\n",
    "\n",
    "for lib in libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"{lib}=={version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{lib} not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GRID P40-24Q\n"
     ]
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "print(torch.cuda.is_available())  # Nếu trả về False, CUDA chưa hoạt động\n",
    "print(torch.cuda.device_count())  # Kiểm tra số lượng GPU\n",
    "print(torch.cuda.get_device_name(0))  # Hiển thị tên GPU\n",
    "# print(torch.set_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(price_dir='data/sample_price/preprocessed/', tweet_dir='data/sample_tweet/raw/', seq_len=5, technical_indicator_dir='data/sample_price/technical_indicator/', llm_summarize='OpenAILLM', wandb=False, data_path='./data/merge_sample.json', output_path='./saved_models/lora-DeepSeek-R1-Distill-Qwen', model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', eval_steps=200, save_steps=200, resume_from_supervised_checkpoint=None, ignore_data_skip='False', num_reflect_trials=2, datasets_dir='./datasets/', local_rank=0, resume_from_reward_checkpoint=False, deepspeed=None, per_device_train_batch_size=4, per_device_eval_batch_size=4, reward_gradient_accumulation_steps=8, reward_learning_rate=3e-05, weight_decay=0.001, reward_base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', bf16=False, num_train_epochs=2, train_subset=100000, eval_subset=50000, gradient_checkpointing=True, optim='adamw_torch', lr_scheduler_type='cosine', reward_adapter='./saved_models/reward_model_deepseek-r1-distill-qwen', rl_base_model='./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged', tokenizer_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', reward_model_name='./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged', log_with=None, rl_learning_rate=2e-05, output_max_length=128, mini_batch_size=4, batch_size=128, ppo_epochs=4, rl_gradient_accumulation_steps=32, adafactor=False, early_stopping=True, target_kl=0.1, reward_baseline=0, batched_gen=True, save_freq=None, output_dir='./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/', seed=0, num_shots=4, save_dir='results/')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/merge_sample.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import transformers\n",
    "import warnings\n",
    "from datasets import load_dataset\n",
    "from predict_module import sft_dataloader\n",
    "\n",
    "# Thiết lập seed\n",
    "fix_seed = 100\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "# Cấu hình tham số cho huấn luyện\n",
    "args = argparse.Namespace(\n",
    "    price_dir=\"data/sample_price/preprocessed/\",  # Thư mục dữ liệu giá\n",
    "    tweet_dir=\"data/sample_tweet/raw/\",  # Thư mục dữ liệu tweet\n",
    "    seq_len=5,  # Độ dài chuỗi đầu vào\n",
    "    technical_indicator_dir=\"data/sample_price/technical_indicator/\",\n",
    "    llm_summarize=\"OpenAILLM\", # OpenAILLM // DeepSeekLLM\n",
    "    wandb=False,  # Tắt logging với Weights & Biases\n",
    "    data_path=\"./data/merge_sample.json\",  # Đường dẫn file dữ liệu\n",
    "    output_path=\"./saved_models/lora-DeepSeek-R1-Distill-Qwen\",  # Thư mục lưu mô hình LoRA\n",
    "    model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Mô hình DeepSeek\n",
    "    eval_steps=200,  # Số bước đánh giá\n",
    "    save_steps=200,  # Số bước lưu checkpoint\n",
    "    resume_from_supervised_checkpoint=None,  # Không resume từ checkpoint\n",
    "    ignore_data_skip=\"False\",  # Không bỏ qua dữ liệu khi resume\n",
    "    num_reflect_trials=2,  # Số lần thử phản ánh\n",
    "    datasets_dir=\"./datasets/\",  # Thư mục datasets\n",
    "    local_rank=0,  # Rank cục bộ cho DDP\n",
    "    resume_from_reward_checkpoint=False,  # Không resume từ reward checkpoint\n",
    "    deepspeed=None,  # Không dùng DeepSpeed\n",
    "    per_device_train_batch_size=4,  # Batch size huấn luyện trên mỗi GPU\n",
    "    per_device_eval_batch_size=4,  # Batch size đánh giá trên mỗi GPU\n",
    "    reward_gradient_accumulation_steps=8,  # Số bước tích lũy gradient cho reward\n",
    "    reward_learning_rate=3e-5,  # Learning rate cho reward\n",
    "    weight_decay=0.001,  # Trọng số giảm dần\n",
    "    reward_base_model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Mô hình reward\n",
    "    bf16=False,  # Sử dụng fp16 thay vì bf16\n",
    "    num_train_epochs=2,  # Số epoch huấn luyện\n",
    "    train_subset=100000,  # Số mẫu huấn luyện\n",
    "    eval_subset=50000,  # Số mẫu đánh giá\n",
    "    gradient_checkpointing=True,  # Bật gradient checkpointing để tiết kiệm VRAM\n",
    "    optim=\"adamw_torch\",  # Optimizer AdamW từ PyTorch\n",
    "    lr_scheduler_type=\"cosine\",  # Lịch trình learning rate kiểu cosine\n",
    "    reward_adapter=\"./saved_models/reward_model_deepseek-r1-distill-qwen\",  # Adapter reward\n",
    "    rl_base_model=\"./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\",  # Mô hình RL\n",
    "    tokenizer_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Tokenizer\n",
    "    reward_model_name=\"./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\",  # Mô hình reward merged\n",
    "    log_with=None,  # Không dùng logging cụ thể\n",
    "    rl_learning_rate=2e-5,  # Learning rate cho RL\n",
    "    output_max_length=128,  # Độ dài đầu ra tối đa\n",
    "    mini_batch_size=4,  # Kích thước mini-batch\n",
    "    batch_size=128,  # Kích thước batch tổng\n",
    "    ppo_epochs=4,  # Số epoch cho PPO\n",
    "    rl_gradient_accumulation_steps=32,  # Số bước tích lũy gradient cho RL\n",
    "    adafactor=False,  # Không dùng Adafactor\n",
    "    early_stopping=True,  # Bật early stopping\n",
    "    target_kl=0.1,  # KL target cho RL\n",
    "    reward_baseline=0,  # Baseline cho reward\n",
    "    batched_gen=True,  # Tạo batch\n",
    "    save_freq=None,  # Tần suất lưu\n",
    "    output_dir=\"./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/\",  # Thư mục lưu checkpoint\n",
    "    seed=0,  # Seed cho RL\n",
    "    num_shots=4,  # Số shots cho few-shot\n",
    "    save_dir=\"results/\"  # Thư mục lưu kết quả\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Args in experiment:\")\n",
    "print(args)\n",
    "\n",
    "args.data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 33\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee62fe52f3064da18c7bccdaac082507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'input_ids', 'labels', 'attention_mask'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# DATA_PATH = args.data_path\n",
    "\n",
    "# data = load_dataset(\"json\", data_files=DATA_PATH)\n",
    "# data['train'][1]\n",
    "\n",
    "# # --- Tải tokenizer ---\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     args.model_path,\n",
    "#     add_eos_token=True,  # Thêm token kết thúc\n",
    "#     local_files_only=args.offline if hasattr(args, 'offline') else False,  # Chế độ offline\n",
    "#     trust_remote_code=True  # Cho DeepSeek\n",
    "# )\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token  # Gán pad_token\n",
    "\n",
    "\n",
    "# CUTOFF_LEN = 256  # Độ dài chuỗi tối đa\n",
    "# data = load_dataset(\"json\", data_files=DATA_PATH)  # Tải JSON dataset\n",
    "# val_set_size = int(0.1 * len(data[\"train\"]))  # Tính validation size\n",
    "# print(data)  # In thông tin dataset\n",
    "\n",
    "# # --- Tải dữ liệu huấn luyện và đánh giá ---\n",
    "# dataloader = sft_dataloader.SFTDataLoader(data, CUTOFF_LEN, val_set_size, tokenizer)  # Định dạng và tokenize\n",
    "# train_data, val_data = dataloader.load_data()  # Chia train/validation\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải mô hình từ: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b0535a9bed46c5ba2305371acc9b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b3de0b676f4218879989ba7a75603b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4924ccc6804d15bb37e43c6f066b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f713bd7dd83544f69638f45c1fd1c977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fde6b995bd4f47972ea14ea583078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 70\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c951b9648f4aa7983f8f3bff99c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baa67e617924d65ad31abb69b89e754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu hình LoRA: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', revision=None, inference_mode=True, r=16, target_modules={'v_proj', 'k_proj', 'q_proj', 'o_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n",
      "Lưu mô hình gộp tại: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "# from trl import SFTTrainer\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, set_peft_model_state_dict\n",
    "\n",
    "\n",
    "def supervised_finetune(args):\n",
    "    # --- Các hằng số huấn luyện ---\n",
    "    MICRO_BATCH_SIZE = args.per_device_train_batch_size  # Batch size mỗi GPU\n",
    "    BATCH_SIZE = args.batch_size  # Batch size tổng\n",
    "    MAX_STEPS = None  # Số bước tối đa, tính động\n",
    "    GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE  # Bước tích lũy gradient\n",
    "    EPOCHS = args.num_train_epochs  # Số epoch\n",
    "    LEARNING_RATE = 3e-4  # Tốc độ học\n",
    "    CUTOFF_LEN = 256  # Độ dài chuỗi tối đa\n",
    "    LORA_R = 16  # Rank LoRA\n",
    "    LORA_ALPHA = 32  # Hệ số scale LoRA\n",
    "    LORA_DROPOUT = 0.05  # Dropout LoRA\n",
    "    VAL_PCT = 0.1  # Tỷ lệ validation\n",
    "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]  # Layer áp dụng LoRA\n",
    "    DATA_PATH = args.data_path  # Đường dẫn dữ liệu\n",
    "    OUTPUT_DIR = args.output_path  # Thư mục lưu mô hình\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))  # Số GPU (DDP)\n",
    "\n",
    "\n",
    "    # --- Xử lý DDP ---\n",
    "    ddp = world_size != 1  # Kiểm tra đa GPU\n",
    "    if ddp:\n",
    "        torch.cuda.set_device(int(os.environ.get(\"LOCAL_RANK\", 0)))  # Gán GPU\n",
    "        GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size  # Chia tích lũy gradient\n",
    "\n",
    "    #==============================================================================================================================\n",
    "    print(f\"Đang tải mô hình từ: {args.model_path}\")  # In đường dẫn mô hình\n",
    "\n",
    "    # Step 3: Load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.model_path,\n",
    "        add_eos_token=True,  # Thêm token kết thúc\n",
    "        local_files_only=args.offline if hasattr(args, 'offline') else False  # Chế độ offline\n",
    "        )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Gán pad_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_path, \n",
    "        torch_dtype=torch.float16, \n",
    "        device_map=\"auto\")\n",
    "\n",
    "    # --- Tải dữ liệu ---\n",
    "    dataset = load_dataset(\"json\", data_files=DATA_PATH)  # Tải JSON dataset\n",
    "\n",
    "\n",
    "    val_set_size = int(VAL_PCT * len(dataset[\"train\"]))  # Tính validation size\n",
    "    print(dataset)  # In thông tin dataset\n",
    "\n",
    "\n",
    "    # --- Tải dữ liệu huấn luyện và đánh giá ---\n",
    "    dataloader = sft_dataloader.SFTDataLoader(dataset, CUTOFF_LEN, val_set_size, tokenizer)  # Định dạng và tokenize\n",
    "    train_data, val_data = dataloader.load_data()  # Chia train/validation\n",
    "    train_data, val_data\n",
    "\n",
    "    # Step 4: Configure LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        r=LORA_R,  # Rank LoRA\n",
    "        lora_alpha=LORA_ALPHA,  # Scale LoRA\n",
    "        target_modules=TARGET_MODULES,  # Layer LoRA\n",
    "        lora_dropout=LORA_DROPOUT,  # Dropout\n",
    "        bias=\"none\",  # Không bias\n",
    "        task_type=\"CAUSAL_LM\"  # Tác vụ ngôn ngữ\n",
    "    )\n",
    "\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "\n",
    "    # --- Tính max_steps ---\n",
    "    now_max_steps = max((len(dataset[\"train\"]) - val_set_size) // BATCH_SIZE * EPOCHS, EPOCHS)  # Số bước tối đa\n",
    "\n",
    "\n",
    "    # --- Xử lý checkpoint ---\n",
    "    if args.resume_from_supervised_checkpoint:  # Nếu có checkpoint\n",
    "        checkpoint_name = os.path.join(args.resume_from_supervised_checkpoint, \"pytorch_model.bin\")  # Đường dẫn checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            pytorch_bin_path = checkpoint_name\n",
    "            checkpoint_name = os.path.join(args.resume_from_supervised_checkpoint, \"adapter_model.bin\")  # Kiểm tra file khác\n",
    "            if os.path.exists(checkpoint_name):\n",
    "                os.rename(checkpoint_name, pytorch_bin_path)  # Đổi tên\n",
    "                warnings.warn(\"Đã đổi tên 'adapter_model.bin' thành 'pytorch_model.bin'\")\n",
    "            else:\n",
    "                args.resume_from_supervised_checkpoint = None  # Bỏ resume\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Tiếp tục từ: {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)  # Tải LoRA\n",
    "            model = set_peft_model_state_dict(model, adapters_weights)  # Áp dụng\n",
    "        else:\n",
    "            print(f\"Không tìm thấy: {checkpoint_name}\")\n",
    "        train_args_path = os.path.join(args.resume_from_supervised_checkpoint, \"trainer_state.json\")  # File trạng thái\n",
    "        if os.path.exists(train_args_path):\n",
    "            base_train_args = json.load(open(train_args_path, 'r'))\n",
    "            base_max_steps = base_train_args[\"max_steps\"]  # Số bước cũ\n",
    "            resume_scale = base_max_steps / now_max_steps\n",
    "            if base_max_steps > now_max_steps:\n",
    "                warnings.warn(f\"Thay epoch {EPOCHS} bằng {base_max_steps}\")\n",
    "                EPOCHS = None\n",
    "                MAX_STEPS = base_max_steps\n",
    "            else:\n",
    "                MAX_STEPS = now_max_steps\n",
    "    else:\n",
    "        MAX_STEPS = now_max_steps\n",
    "\n",
    "\n",
    "    # Step 5: Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,  # Directory to save results\n",
    "        per_device_train_batch_size=MICRO_BATCH_SIZE,  # Batch size GPU\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,  # Tích lũy gradient\n",
    "        warmup_steps=100,  # Bước khởi động\n",
    "        num_train_epochs=EPOCHS if EPOCHS else 1,  # Epoch\n",
    "        max_steps=MAX_STEPS,  # Số bước tối đa\n",
    "        learning_rate=LEARNING_RATE,  # Tốc độ học\n",
    "        bf16=args.bf16,  # BF16\n",
    "        fp16=not args.bf16,  # FP16\n",
    "        logging_steps=20,  # Log mỗi 20 bước\n",
    "        eval_strategy=\"steps\" if val_set_size > 0 else \"no\",  # Đánh giá\n",
    "        save_strategy=\"steps\",  # Lưu checkpoint\n",
    "        eval_steps=args.eval_steps if val_set_size > 0 else None,  # Bước đánh giá\n",
    "        save_steps=args.save_steps,  # Bước lưu\n",
    "        save_total_limit=30,  # Số checkpoint tối đa\n",
    "        load_best_model_at_end=True if val_set_size > 0 else False,  # Tải mô hình tốt\n",
    "        ddp_find_unused_parameters=False if ddp else None,  # Tối ưu DDP\n",
    "        report_to=\"wandb\" if args.wandb else [],  # Báo cáo WandB\n",
    "        optim=args.optim,  # Bộ tối ưu\n",
    "        lr_scheduler_type=args.lr_scheduler_type,  # Scheduler\n",
    "        remove_unused_columns=True,  # Xóa cột thừa\n",
    "        max_grad_norm=1.0,  # Giới hạn gradient\n",
    "    )\n",
    "\n",
    "\n",
    "    # Step 6: Initialize the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data, \n",
    "        eval_dataset=val_data,  # Small evaluation set\n",
    "        data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    # Step 7: Train the model\n",
    "    trainer.train(resume_from_checkpoint=args.resume_from_supervised_checkpoint)\n",
    "    \n",
    "    model.save_pretrained(OUTPUT_DIR) \n",
    "\n",
    "# --- Chạy huấn luyện ---\n",
    "\n",
    "supervised_finetune(args)\n",
    "\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "\n",
    "# --- Gộp adapter LoRA ---\n",
    "merge_peft_adapter(model_name=args.output_path, output_name=args.rl_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Giải phóng bộ nhớ trên GPU\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: ./datasets/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 546,304 || all params: 1,544,262,144 || trainable%: 0.0354\n",
      "train_dataset:  3\n",
      "train_dataset:  3\n",
      "eval_dataset:  3\n",
      "eval_dataset:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving last checkpoint of the model\n",
      "Cấu hình LoRA: LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', revision=None, inference_mode=True, r=4, target_modules={'q_proj', 'v_proj'}, exclude_modules=None, lora_alpha=8, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=['classifier', 'score'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n",
      "Lưu mô hình gộp tại: ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerBase,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "from predict_module import rm_dataloader\n",
    "\n",
    "def train_reward_model(args):\n",
    "    script_args = args\n",
    "    dataset_name = script_args.datasets_dir\n",
    "    print(\"dataset_name:\", dataset_name)\n",
    "    \n",
    "    output_name = script_args.reward_adapter\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_name,\n",
    "        learning_rate=script_args.reward_learning_rate,\n",
    "        per_device_train_batch_size=1,  # Giảm batch size\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=script_args.num_train_epochs,\n",
    "        weight_decay=script_args.weight_decay,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=16,  # Tăng gradient accumulation\n",
    "        gradient_checkpointing=False,  # Tắt gradient checkpointing\n",
    "        deepspeed=None,  # Tắt DeepSpeed để kiểm tra\n",
    "        remove_unused_columns=False,\n",
    "        label_names=[],\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=10,\n",
    "        optim=script_args.optim,\n",
    "        lr_scheduler_type=script_args.lr_scheduler_type,\n",
    "        report_to=\"none\",\n",
    "        no_cuda=False,  # Đảm bảo dùng GPU\n",
    "        bf16=True,\n",
    "    )\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(script_args.reward_base_model, trust_remote_code=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        script_args.reward_base_model,\n",
    "        num_labels=1,\n",
    "        torch_dtype=torch.bfloat16,  # Thử bfloat16\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    # # Handle pad token\n",
    "    # if tokenizer.pad_token is None:\n",
    "    #     tokenizer.pad_token = tokenizer.eos_token\n",
    "    #     model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    # else:\n",
    "    #     model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Set device\n",
    "    # device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # print(\"device_map:\", device_map)\n",
    "    # model = model.to(device_map)  # Chuyển thủ công\n",
    "    \n",
    "    # LoRA config\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=4,  # Giảm r\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    num_proc = 1\n",
    "    reward_dataloder = rm_dataloader.RewardDataLoader(dataset_name, script_args.train_subset, script_args.eval_subset, num_proc, tokenizer)\n",
    "    train_dataset, eval_dataset = reward_dataloder.load_data()\n",
    "    \n",
    "    @dataclass\n",
    "    class RewardDataCollatorWithPadding:\n",
    "        tokenizer: PreTrainedTokenizerBase\n",
    "        padding: Union[bool, str, PaddingStrategy] = True\n",
    "        max_length: Optional[int] = None\n",
    "        pad_to_multiple_of: Optional[int] = None\n",
    "        return_tensors: str = \"pt\"\n",
    "\n",
    "        def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "            features_j = []\n",
    "            features_k = []\n",
    "            for feature in features:\n",
    "                features_j.append(\n",
    "                    {\n",
    "                        \"input_ids\": feature[\"input_ids_j\"],\n",
    "                        \"attention_mask\": feature[\"attention_mask_j\"],\n",
    "                    }\n",
    "                )\n",
    "                features_k.append(\n",
    "                    {\n",
    "                        \"input_ids\": feature[\"input_ids_k\"],\n",
    "                        \"attention_mask\": feature[\"attention_mask_k\"],\n",
    "                    }\n",
    "                )\n",
    "            batch_j = self.tokenizer.pad(\n",
    "                features_j,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "                return_tensors=self.return_tensors,\n",
    "            )\n",
    "            batch_k = self.tokenizer.pad(\n",
    "                features_k,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "                return_tensors=self.return_tensors,\n",
    "            )\n",
    "            batch = {\n",
    "                \"input_ids_j\": batch_j[\"input_ids\"],\n",
    "                \"attention_mask_j\": batch_j[\"attention_mask\"].to(dtype=torch.bfloat16),\n",
    "                \"input_ids_k\": batch_k[\"input_ids\"],\n",
    "                \"attention_mask_k\": batch_k[\"attention_mask\"].to(dtype=torch.bfloat16),\n",
    "                \"return_loss\": True,\n",
    "            }\n",
    "            return batch\n",
    "    \n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, _ = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=0)\n",
    "        labels = np.zeros(predictions.shape)\n",
    "        return accuracy.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    class RewardTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "            rewards_j = model(\n",
    "                input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n",
    "            rewards_k = model(\n",
    "                input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n",
    "            loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()\n",
    "            if return_outputs:\n",
    "                return loss, {\"rewards_j\": rewards_j, \"rewards_k\": rewards_k}\n",
    "            return loss\n",
    "    \n",
    "    trainer = RewardTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=RewardDataCollatorWithPadding(\n",
    "            tokenizer=tokenizer, max_length=512, pad_to_multiple_of=8),\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = True\n",
    "    trainer.train(script_args.resume_from_reward_checkpoint)\n",
    "    \n",
    "    print(\"Saving last checkpoint of the model\")\n",
    "    model.save_pretrained(output_name)\n",
    "\n",
    "train_reward_model(args)\n",
    "\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "merge_peft_adapter(model_name=args.reward_adapter, output_name=args.reward_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giải phóng bộ nhớ trên GPU\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# from transformers import DataCollatorWithPadding, AutoTokenizer\n",
    "\n",
    "\n",
    "# def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "#     \"\"\"\n",
    "#     Tạo dataset cho huấn luyện PPO.\n",
    "    \n",
    "#     Args:\n",
    "#         tokenizer: Tokenizer để mã hóa văn bản.\n",
    "#         dataset_name: Tên hoặc đường dẫn dataset.\n",
    "#         input_min_text_length: Độ dài tối thiểu của câu hỏi.\n",
    "#         input_max_text_length: Độ dài tối đa của câu hỏi.\n",
    "    \n",
    "#     Returns:\n",
    "#         Dataset đã được xử lý với các cột query và input_ids.\n",
    "#     \"\"\"\n",
    "#     ds = load_dataset(dataset_name, split=\"train\")\n",
    "#     original_columns = ds.column_names\n",
    "#     def preprocess_function(examples):\n",
    "#         new_examples = {\n",
    "#             \"query\": [],\n",
    "#             \"input_ids\": [],\n",
    "#         }\n",
    "#         # Giả định dataset có cột 'user_input' hoặc 'question'\n",
    "#         input_key = \"user_input\" if \"user_input\" in examples else \"question\"\n",
    "#         for question in examples[input_key]:\n",
    "#             query = \"Question: \" + question + \"\\n\\nAnswer: \"\n",
    "#             tokenized_question = tokenizer(\n",
    "#                 query,\n",
    "#                 truncation=True,\n",
    "#                 max_length=512,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             )\n",
    "#             new_examples[\"query\"].append(query)\n",
    "#             new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"].squeeze(0))\n",
    "#         return new_examples\n",
    "\n",
    "#     ds = ds.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         num_proc=1,\n",
    "#         remove_columns=original_columns,\n",
    "#     )\n",
    "#     ds.set_format(type=\"torch\")\n",
    "#     return ds\n",
    "\n",
    "#     # Tạo dataset\n",
    "#     dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "\n",
    "# dataset_name = args.datasets_dir\n",
    "\n",
    "# ds = load_dataset(dataset_name, split=\"train\")\n",
    "# ds\n",
    "\n",
    "# tokenizer_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# # Tải tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "    \n",
    "# dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "\n",
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_model_name: ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\n",
      "dataset_name: ./datasets/\n",
      "model_name: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\n",
      "train_dataset size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: LlamaTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e2f666cc734bdf8d357ed6c80019cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 64 samples\n",
      "Finetune model: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged <class 'trl.models.modeling_value_head.AutoModelForCausalLMWithValueHead'>\n",
      "Dataset({\n",
      "    features: ['query', 'input_ids'],\n",
      "    num_rows: 64\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "0it [00:00, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/.venv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "10it [05:20, 32.65s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "16it [08:50, 33.17s/it]\n",
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1431: UserWarning: Cannot retrieve user information assuming you are running in offline mode.\n",
      "  warnings.warn(\"Cannot retrieve user information assuming you are running in offline mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final checkpoint saved at: ./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/step_saved\n",
      "Cấu hình LoRA: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged', revision=None, inference_mode=True, r=8, target_modules={'q_proj', 'v_proj', 'o_proj', 'k_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu mô hình gộp tại: ./saved_models/sep_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3391: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb569fd29cd49df8db2c6e5aac57771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import Adafactor, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, AutoModelForCausalLM, DataCollatorWithPadding\n",
    "from transformers import GenerationConfig, pipeline\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "from trl.core import LengthSampler\n",
    "from trl import create_reference_model\n",
    "import os\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def tuning_lm_with_rl(args):\n",
    "    # Khởi tạo script_args từ args\n",
    "    script_args = args\n",
    "    reward_model_name = script_args.reward_model_name\n",
    "    print(\"reward_model_name:\", reward_model_name)\n",
    "\n",
    "    # Đường dẫn dataset\n",
    "    dataset_name = script_args.datasets_dir\n",
    "    print(\"dataset_name:\", dataset_name)\n",
    "\n",
    "    # Cấu hình PPO\n",
    "    config = PPOConfig(\n",
    "        learning_rate=script_args.rl_learning_rate,\n",
    "        # batch_size=script_args.batch_size,\n",
    "        batch_size=4,\n",
    "        # mini_batch_size=script_args.mini_batch_size,\n",
    "        mini_batch_size=2,\n",
    "        # gradient_accumulation_steps=script_args.rl_gradient_accumulation_steps,\n",
    "        gradient_accumulation_steps=1,\n",
    "        ppo_epochs=script_args.ppo_epochs,  \n",
    "        seed=script_args.seed,\n",
    "    )\n",
    "\n",
    "    # Tên mô hình gốc\n",
    "    model_name = script_args.rl_base_model\n",
    "    print(\"model_name:\", model_name)\n",
    "\n",
    "    # Tải dataset\n",
    "    train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    print(\"train_dataset size:\", len(train_dataset))\n",
    "\n",
    "    # Cấu hình tham số cho sentiment pipeline\n",
    "    sent_kwargs = {\n",
    "        \"return_all_scores\": True,\n",
    "        \"function_to_apply\": \"none\",\n",
    "        \"batch_size\": 1,\n",
    "        \"truncation\": True\n",
    "    }\n",
    "\n",
    "    # Tải tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(script_args.tokenizer_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"Tokenizer loaded:\", tokenizer.__class__.__name__)\n",
    "\n",
    "    def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "        \"\"\"\n",
    "        Tạo dataset cho huấn luyện PPO.\n",
    "        \n",
    "        Args:\n",
    "            tokenizer: Tokenizer để mã hóa văn bản.\n",
    "            dataset_name: Tên hoặc đường dẫn dataset.\n",
    "            input_min_text_length: Độ dài tối thiểu của câu hỏi.\n",
    "            input_max_text_length: Độ dài tối đa của câu hỏi.\n",
    "        \n",
    "        Returns:\n",
    "            Dataset đã được xử lý với các cột query và input_ids.\n",
    "        \"\"\"\n",
    "        ds = load_dataset(dataset_name, split=\"train\")\n",
    "        # Giả sử dataset của bạn tên là `ds`, hiện có 6 dòng\n",
    "        repeat_factor = 64 // len(ds) + 1  # Lặp đủ số lần để vượt 64\n",
    "\n",
    "        # Lặp lại nhiều lần rồi cắt còn đúng 64\n",
    "        ds = concatenate_datasets([ds] * repeat_factor)\n",
    "        ds = ds.select(range(64))  # Lấy đúng 64 dòng\n",
    "        original_columns = ds.column_names\n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            new_examples = {\n",
    "                \"query\": [],\n",
    "                \"input_ids\": [],\n",
    "            }\n",
    "            # Giả định dataset có cột 'user_input' hoặc 'question'\n",
    "            input_key = \"user_input\" if \"user_input\" in examples else \"question\"\n",
    "            for question in examples[input_key]:\n",
    "                query = \"Question: \" + question + \"\\n\\nAnswer: \"\n",
    "                tokenized_question = tokenizer(\n",
    "                    query,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                new_examples[\"query\"].append(query)\n",
    "                new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"].squeeze(0))\n",
    "            return new_examples\n",
    "\n",
    "        ds = ds.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=original_columns,\n",
    "        )\n",
    "        ds.set_format(type=\"torch\")\n",
    "        return ds\n",
    "\n",
    "    # Tạo dataset\n",
    "    dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "    print(\"Dataset created with\", len(dataset), \"samples\")\n",
    "\n",
    "    def collator(data):\n",
    "        \"\"\"\n",
    "        Collator để xử lý batch dữ liệu.\n",
    "        \"\"\"\n",
    "        return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "    # def collator(data):\n",
    "    #     \"\"\"\n",
    "    #     Custom collator cho PPOTrainer.\n",
    "    #     Dữ liệu đầu vào là list[dict], mỗi dict chứa:\n",
    "    #         - \"query\": str\n",
    "    #         - \"input_ids\": Tensor (1D)\n",
    "    #     \"\"\"\n",
    "    #     input_ids = [item[\"input_ids\"] for item in data]\n",
    "    #     queries = [item[\"query\"] for item in data]\n",
    "\n",
    "    #     # Pad input_ids thủ công nếu cần\n",
    "    #     input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    #     return {\n",
    "    #         \"input_ids\": input_ids,\n",
    "    #         \"query\": queries,\n",
    "    #     }\n",
    "\n",
    "    # Đặt seed để đảm bảo tính tái lập\n",
    "    torch.manual_seed(config.seed)\n",
    "\n",
    "    # Cấu hình LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "    )\n",
    "\n",
    "    # Tải mô hình chính với value head\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,  # Đồng bộ với reward model\n",
    "        peft_config=lora_config,\n",
    "    )\n",
    "\n",
    "    # Gán thủ công base_model_prefix để tránh lỗi\n",
    "    model.base_model_prefix = \"model\"  # hoặc \"transformer\", tùy thuộc vào tên trong mô hình gốc\n",
    "    # Gán generation_config để tránh lỗi AttributeError\n",
    "    model.generation_config = GenerationConfig.from_pretrained(\n",
    "        \"./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\"\n",
    "    )\n",
    "    # model.config.return_dict = True\n",
    "\n",
    "    # try:\n",
    "    #     model.base_model.model.config.return_dict = True\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "    # # Tải mô hình giá trị (value model) với value head\n",
    "    # value_model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     model_name,\n",
    "    #     torch_dtype=torch.bfloat16,\n",
    "    #     trust_remote_code=True,\n",
    "    # )\n",
    "    # # value_model = get_peft_model(value_model, lora_config)\n",
    "    # def force_return_dict_recursively(model):\n",
    "    #     \"\"\"\n",
    "    #     Recursively patch forward function of all relevant submodules to enforce return_dict=True.\n",
    "    #     \"\"\"\n",
    "    #     if hasattr(model, 'forward'):\n",
    "    #         original_forward = model.forward\n",
    "\n",
    "    #         def patched_forward(*args, **kwargs):\n",
    "    #             kwargs[\"return_dict\"] = True\n",
    "    #             return original_forward(*args, **kwargs)\n",
    "\n",
    "    #         model.forward = patched_forward\n",
    "\n",
    "    #     # Patch model.base_model.model nếu có\n",
    "    #     if hasattr(model, \"base_model\") and hasattr(model.base_model, \"model\"):\n",
    "    #         force_return_dict_recursively(model.base_model.model)\n",
    "\n",
    "    #     return model\n",
    "\n",
    "    # # Sau khi load:\n",
    "    # model = force_return_dict_recursively(model)\n",
    "    # value_model = force_return_dict_recursively(value_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Tạo generation_config nếu không có\n",
    "    if not hasattr(model, \"generation_config\"):\n",
    "        model.generation_config = GenerationConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    print(\"Finetune model:\", model_name, type(model))\n",
    "\n",
    "    # # Tải reward model từ checkpoint\n",
    "    # reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    #     reward_model_name,\n",
    "    #     torch_dtype=torch.bfloat16,\n",
    "    #     trust_remote_code=True,\n",
    "    # )\n",
    "    # reward_model_config = AutoConfig.from_pretrained(reward_model_name, trust_remote_code=True)\n",
    "    # print(\"Reward model:\", type(reward_model))\n",
    "\n",
    "    # Tạo optimizer (nếu dùng Adafactor)\n",
    "    optimizer = None\n",
    "    if script_args.adafactor:\n",
    "        optimizer = Adafactor(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            scale_parameter=False,\n",
    "            relative_step=False,\n",
    "            warmup_init=False,\n",
    "            lr=config.learning_rate,\n",
    "        )\n",
    "\n",
    "    # Khởi tạo PPOTrainer\n",
    "    print(dataset)\n",
    "    ppo_trainer = PPOTrainer(\n",
    "        config=config,  # Sử dụng args thay vì config\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,  \n",
    "        # reward_model=reward_model,\n",
    "        # ref_model = None,\n",
    "        # value_model=value_model,\n",
    "        dataset=dataset,\n",
    "        data_collator=collator,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    # ppo_trainer.train()\n",
    "\n",
    "    # Xác định thiết bị\n",
    "    device = ppo_trainer.accelerator.device\n",
    "    if ppo_trainer.accelerator.num_processes == 1:\n",
    "        device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Tạo sentiment pipeline\n",
    "    sentiment_pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=reward_model_name,\n",
    "        device_map=\"auto\",\n",
    "        # config=reward_model_config,\n",
    "        tokenizer=tokenizer,\n",
    "        # device=device,\n",
    "    )\n",
    "\n",
    "    # Cấu hình tham số sinh văn bản\n",
    "    generation_kwargs = {\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 1.0,\n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    output_min_length = 32\n",
    "    output_max_length = script_args.output_max_length\n",
    "    output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "    # Vòng lặp huấn luyện PPO\n",
    "    for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "        question_tensors = batch[\"input_ids\"]\n",
    "\n",
    "        # Sinh phản hồi\n",
    "        response_tensors = ppo_trainer.generate(\n",
    "            question_tensors,\n",
    "            return_prompt=False,\n",
    "            length_sampler=output_length_sampler,\n",
    "            **generation_kwargs,\n",
    "        )\n",
    "        batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "        # Tính điểm thưởng từ reward model\n",
    "        texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "        pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "        rewards = [torch.tensor(output[0][\"score\"] - script_args.reward_baseline) for output in pipe_outputs]\n",
    "\n",
    "        # Thực hiện bước PPO\n",
    "        stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "        ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "        # Lưu checkpoint định kỳ\n",
    "        if script_args.save_freq and epoch and epoch % script_args.save_freq == 0:\n",
    "            save_dir = os.path.join(script_args.output_dir, f\"step_{epoch}\")\n",
    "            ppo_trainer.save_pretrained(save_dir)\n",
    "            print(f\"Saved checkpoint at: {save_dir}\")\n",
    "\n",
    "    # Lưu checkpoint cuối cùng\n",
    "    final_save_dir = os.path.join(script_args.output_dir, \"step_saved\")\n",
    "    ppo_trainer.save_pretrained(final_save_dir)\n",
    "    print(f\"Final checkpoint saved at: {final_save_dir}\")\n",
    "\n",
    "# Chạy hàm\n",
    "tuning_lm_with_rl(args)\n",
    "\n",
    "# # Gộp adapter LoRA\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "merge_peft_adapter(\n",
    "    model_name=os.path.join(args.output_dir, \"step_saved\"),\n",
    "    output_name=\"./saved_models/sep_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SUMMARIZE Tập Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from explain_module.agents import PredictReflectAgent\n",
    "# from data_load.dataloader import DataLoader\n",
    "\n",
    "# dataloader = DataLoader(args)\n",
    "\n",
    "# print(\"Loading Test Agents...\")\n",
    "# data_test = dataloader.load(flag=\"test\")\n",
    "\n",
    "# # Lưu DataFrame vào tệp CSV\n",
    "# path = args.llm_summarize+\"_data_test.csv\"\n",
    "# data_test.to_csv(path, index=False)  # index=False để không lưu chỉ số dòng\n",
    "# print(f\"DataFrame đã được lưu vào '{path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thêm Technical Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import pandas_ta as ta  # Sử dụng pandas_ta vì dễ cài đặt và tích hợp với pandas\n",
    "# import numpy as np\n",
    "\n",
    "# def format_technical_indicators(row):\n",
    "#     \"\"\"\n",
    "#     Chuyển đổi một dòng của DataFrame thành văn bản, bỏ qua giá trị NaN.\n",
    "\n",
    "#     Args:\n",
    "#         row (pd.Series): Một dòng của DataFrame chứa các chỉ số kỹ thuật.\n",
    "\n",
    "#     Returns:\n",
    "#         str: Văn bản chứa chỉ số kỹ thuật, mỗi dòng cách nhau bởi '\\n'.\n",
    "#     \"\"\"\n",
    "#     lines = []\n",
    "    \n",
    "#     for col, value in row.items():\n",
    "#         if pd.notna(value):  # Bỏ qua nếu giá trị là NaN\n",
    "#             lines.append(f\"{col}: {value:,}\")  # Định dạng số với dấu phẩy\n",
    "    \n",
    "#     return \"\\n\".join(lines)  # Kết hợp các dòng thành văn bản\n",
    "\n",
    "\n",
    "# # Đọc file CSV vào DataFrame\n",
    "# data = pd.read_csv(\"data_test.csv\")\n",
    "\n",
    "\n",
    "# def add_technical_indicator(data):\n",
    "#     # Lấy danh sách các giá trị duy nhất của cột \"ticker\"\n",
    "#     unique_tickers = data[\"ticker\"].unique()\n",
    "#     unique_tickers\n",
    "\n",
    "#     technical_indicator_dir = \"data/sample_price/technical_indicator/\"\n",
    "#     # DataFrame để lưu kết quả cuối cùng\n",
    "#     final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#     for file_name in unique_tickers:\n",
    "\n",
    "#         technical_indicator_path = os.path.join(technical_indicator_dir, file_name + \".csv\")\n",
    "\n",
    "#         df_technical_indicator = pd.read_csv(technical_indicator_path)\n",
    "\n",
    "#         # Loại bỏ cột 'Date' để chỉ giữ các chỉ báo kỹ thuật\n",
    "#         df_technical_indicator[\"technical_indicator\"] = df_technical_indicator.drop(columns=[\"Date\"]).apply(format_technical_indicators, axis=1)\n",
    "\n",
    "#         # Thêm cột \"ticker\" với giá trị file_name\n",
    "#         df_technical_indicator[\"ticker\"] = file_name\n",
    "\n",
    "#         # Hiển thị kết quả  \n",
    "#         df_technical_indicator = df_technical_indicator[[\"ticker\", \"Date\", \"technical_indicator\"]].rename(columns={\"Date\": \"date\"})\n",
    "#         # Merge theo 2 cột \"ticker\" và \"Date\"\n",
    "#         merged_df = pd.merge(data, df_technical_indicator, on=[\"ticker\", \"date\"], how=\"inner\")\n",
    "\n",
    "#         # Cộng dồn kết quả\n",
    "#         final_df = pd.concat([final_df, merged_df], ignore_index=True)\n",
    "\n",
    "#     return final_df\n",
    "\n",
    "    \n",
    "\n",
    "# data = add_technical_indicator(data)\n",
    "# data\n",
    "\n",
    "# data.to_csv(\"data_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHẠY TẬP TEST\n",
    "*** chú ý: Kích thước tập Test chưa được chạy toàn bộ (data = data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>summary</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>technical_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021-12-05\\nAmazon (AMZN) is making its own co...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>SMA_5: 174.01\\nEMA_5: 173.63\\nMACD: 0.05\\nMACD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021-12-29\\n- Amazon's stock symbol is $AMZN.\\...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>SMA_5: 169.13\\nEMA_5: 169.2\\nMACD: -1.23\\nMACD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                                            summary    target  \\\n",
       "0   AMZN  2021-12-05\\nAmazon (AMZN) is making its own co...  Negative   \n",
       "1   AMZN  2021-12-29\\n- Amazon's stock symbol is $AMZN.\\...  Positive   \n",
       "\n",
       "         date                                technical_indicator  \n",
       "0  2021-12-10  SMA_5: 174.01\\nEMA_5: 173.63\\nMACD: 0.05\\nMACD...  \n",
       "1  2022-01-03  SMA_5: 169.13\\nEMA_5: 169.2\\nMACD: -1.23\\nMACD...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "\n",
    "# Đọc tệp CSV\n",
    "data = pd.read_csv(args.llm_summarize+\"_data_test.csv\")\n",
    "data = data[:2]\n",
    "data\n",
    "\n",
    "\n",
    "# agent_cls = PredictReflectAgent\n",
    "# test_agents = [agent_cls(row['ticker'], row['summary'], row['target']) for _, row in data.iterrows()]\n",
    "# print(\"Loaded Test Agents.\")\n",
    "# test_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import GenerationConfig, pipeline\n",
    "\n",
    "\n",
    "def test(args):\n",
    "\n",
    "    # Đọc tệp CSV\n",
    "    data = pd.read_csv(args.llm_summarize+\"_data_test.csv\")\n",
    "    data = data[:2] # Giảm kích thước tập Test để chạy nhanh hơn\n",
    "\n",
    "\n",
    "    #==========================================================================\n",
    "    # print(\"Loading Test Agents...\")\n",
    "    # data = self.dataloader.load(flag=\"test\")\n",
    "    # print(\"Test data loaded with columns:\", data.columns.tolist())\n",
    "    # print(\"Number of test samples:\", len(data))\n",
    "    #==========================================================================\n",
    "\n",
    "    agent_cls = PredictReflectAgent\n",
    "    test_agents = [agent_cls(row['ticker'], row['summary'], row['target'], row['technical_indicator'], '') for _, row in data.iterrows()]\n",
    "    print(\"Loaded Test Agents:\", len(test_agents))\n",
    "\n",
    "\n",
    "    tokenizer_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        \"./saved_models/sep_model\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    reward_model = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=args.reward_model_name,\n",
    "        device_map=\"auto\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    for agent in test_agents:\n",
    "        agent.run_n_shots(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            reward_model=reward_model,\n",
    "            num_shots=args.num_shots\n",
    "        )\n",
    "\n",
    "    correct, incorrect = summarize_trial(test_agents)\n",
    "    print(f'Finished evaluation, Correct: {len(correct)}, Incorrect: {len(incorrect)}')\n",
    "\n",
    "    save_results(test_agents, args.save_dir)\n",
    "    print(f\"kết quả được lưu vào fie {args.save_dir}\")\n",
    "\n",
    "test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Đọc Kết Quả và tính Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\nExplanation: Amazon's strong fourth...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Amazon's strong fourth-quarter performance, dr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\nExplanation: Amazon's strong Q3 perf...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Amazon's strong Q3 performance, strong cash re...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  Given a list of facts and a set of technical i...   \n",
       "1  Given a list of facts and a set of technical i...   \n",
       "\n",
       "                                            Response      Trend  \\\n",
       "0   Positive\\nExplanation: Amazon's strong fourth...   Positive   \n",
       "1  Positive\\nExplanation: Amazon's strong Q3 perf...   Positive   \n",
       "\n",
       "                                         Explanation    Target  \n",
       "0  Amazon's strong fourth-quarter performance, dr...  Negative  \n",
       "1  Amazon's strong Q3 performance, strong cash re...  Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.read_csv(\"results/results.csv\")\n",
    "df_result\n",
    "\n",
    "# Tách cột 'Response' thành hai cột mới\n",
    "df_result[['Trend', 'Explanation']] = df_result['Response'].str.split(r'\\nExplanation:\\s*', expand=True)\n",
    "df_result # Đặt lại thứ tự cột\n",
    "df_result = df_result[['Prompt', 'Response', 'Trend', 'Explanation', 'Target']]\n",
    "df_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính Accuracy và MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n",
      "MCC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "y_pred = df_result[\"Trend\"]\n",
    "y_true = df_result[\"Target\"]\n",
    "\n",
    "# Tính accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Tính MCC\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
