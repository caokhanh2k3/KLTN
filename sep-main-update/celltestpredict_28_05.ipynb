{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.5.0\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install openai==1.79.0\n",
    "# !pip install tenacity==9.1.2\n",
    "# !pip install tiktoken==0.9.0\n",
    "# !pip install transformers==4.51.3\n",
    "# !pip install pandas==2.2.3\n",
    "# !pip install scikit-learn==1.6.1\n",
    "# !pip install bitsandbytes==0.45.5\n",
    "# !pip install datasets==3.6.0\n",
    "# !pip install sentencepiece==0.2.0\n",
    "# !pip install peft==0.15.2\n",
    "# !pip install evaluate==0.4.3\n",
    "# !pip install trl==0.11.4\n",
    "# !pip install protobuf==6.31.0\n",
    "# !pip install python-dotenv==1.1.0\n",
    "# !pip install pandas_ta\n",
    "# !pip install ollama==0.4.8\n",
    "# !pip install accelerate==1.7.0\n",
    "# !pip install ipywidgets\n",
    "# !pip install pynvml==8.1.7\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.26.4\n",
      "openai==1.79.0\n",
      "tenacity==9.1.2\n",
      "tiktoken==0.9.0\n",
      "transformers==4.51.3\n",
      "pandas==2.2.3\n",
      "scikit-learn==1.6.1\n",
      "torch==2.5.0+cu124\n",
      "bitsandbytes==0.45.5\n",
      "datasets==3.6.0\n",
      "sentencepiece==0.2.0\n",
      "peft==0.15.2\n",
      "evaluate==0.4.3\n",
      "trl==0.11.4\n",
      "protobuf==6.31.0\n",
      "python-dotenv==1.1.0\n",
      "pandas_ta==0.3.14b0\n",
      "ollama==0.4.8\n",
      "accelerate==1.7.0\n",
      "ipywidgets==8.1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5990/316775683.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "libs = [\n",
    "    \"numpy\", \"openai\", \"tenacity\", \"tiktoken\", \"transformers\", \"pandas\",\n",
    "    \"scikit-learn\", \"torch\", \"bitsandbytes\", \"datasets\", \"sentencepiece\",\n",
    "    \"peft\", \"evaluate\", \"trl\", \"protobuf\", \"python-dotenv\", \"pandas_ta\",\n",
    "    \"ollama\", \"accelerate\", \"ipywidgets\"\n",
    "]\n",
    "\n",
    "for lib in libs:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        print(f\"{lib}=={version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{lib} not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GRID P40-24Q\n"
     ]
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "print(torch.cuda.is_available())  # Nếu trả về False, CUDA chưa hoạt động\n",
    "print(torch.cuda.device_count())  # Kiểm tra số lượng GPU\n",
    "print(torch.cuda.get_device_name(0))  # Hiển thị tên GPU\n",
    "# print(torch.set_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(price_dir='data/sample_price/preprocessed/', tweet_dir='data/sample_tweet/raw/', seq_len=5, technical_indicator_dir='data/sample_price/technical_indicator/', llm_summarize='OpenAILLM', wandb=False, data_path='./data/merge_sample.json', output_path='./saved_models/lora-DeepSeek-R1-Distill-Qwen', model_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', eval_steps=200, save_steps=200, resume_from_supervised_checkpoint=None, ignore_data_skip='False', num_reflect_trials=2, datasets_dir='./datasets/', local_rank=0, resume_from_reward_checkpoint=False, deepspeed=None, per_device_train_batch_size=4, per_device_eval_batch_size=4, reward_gradient_accumulation_steps=8, reward_learning_rate=3e-05, weight_decay=0.001, reward_base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', bf16=False, num_train_epochs=2, train_subset=100000, eval_subset=50000, gradient_checkpointing=True, optim='adamw_torch', lr_scheduler_type='cosine', reward_adapter='./saved_models/reward_model_deepseek-r1-distill-qwen', rl_base_model='./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged', tokenizer_name='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', reward_model_name='./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged', log_with=None, rl_learning_rate=2e-05, output_max_length=128, mini_batch_size=4, batch_size=128, ppo_epochs=4, rl_gradient_accumulation_steps=32, adafactor=False, early_stopping=True, target_kl=0.1, reward_baseline=0, batched_gen=True, save_freq=None, output_dir='./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/', seed=0, num_shots=4, save_dir='results/')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/merge_sample.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import transformers\n",
    "import warnings\n",
    "from datasets import load_dataset\n",
    "from predict_module import sft_dataloader\n",
    "\n",
    "# Thiết lập seed\n",
    "fix_seed = 100\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "# Cấu hình tham số cho huấn luyện\n",
    "args = argparse.Namespace(\n",
    "    price_dir=\"data/sample_price/preprocessed/\",  # Thư mục dữ liệu giá\n",
    "    tweet_dir=\"data/sample_tweet/raw/\",  # Thư mục dữ liệu tweet\n",
    "    seq_len=5,  # Độ dài chuỗi đầu vào\n",
    "    technical_indicator_dir=\"data/sample_price/technical_indicator/\",\n",
    "    llm_summarize=\"OpenAILLM\", # OpenAILLM // DeepSeekLLM\n",
    "    wandb=False,  # Tắt logging với Weights & Biases\n",
    "    data_path=\"./data/merge_sample.json\",  # Đường dẫn file dữ liệu\n",
    "    output_path=\"./saved_models/lora-DeepSeek-R1-Distill-Qwen\",  # Thư mục lưu mô hình LoRA\n",
    "    model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Mô hình DeepSeek\n",
    "    eval_steps=200,  # Số bước đánh giá\n",
    "    save_steps=200,  # Số bước lưu checkpoint\n",
    "    resume_from_supervised_checkpoint=None,  # Không resume từ checkpoint\n",
    "    ignore_data_skip=\"False\",  # Không bỏ qua dữ liệu khi resume\n",
    "    num_reflect_trials=2,  # Số lần thử phản ánh\n",
    "    datasets_dir=\"./datasets/\",  # Thư mục datasets\n",
    "    local_rank=0,  # Rank cục bộ cho DDP\n",
    "    resume_from_reward_checkpoint=False,  # Không resume từ reward checkpoint\n",
    "    deepspeed=None,  # Không dùng DeepSpeed\n",
    "    per_device_train_batch_size=4,  # Batch size huấn luyện trên mỗi GPU\n",
    "    per_device_eval_batch_size=4,  # Batch size đánh giá trên mỗi GPU\n",
    "    reward_gradient_accumulation_steps=8,  # Số bước tích lũy gradient cho reward\n",
    "    reward_learning_rate=3e-5,  # Learning rate cho reward\n",
    "    weight_decay=0.001,  # Trọng số giảm dần\n",
    "    reward_base_model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Mô hình reward\n",
    "    bf16=False,  # Sử dụng fp16 thay vì bf16\n",
    "    num_train_epochs=2,  # Số epoch huấn luyện\n",
    "    train_subset=100000,  # Số mẫu huấn luyện\n",
    "    eval_subset=50000,  # Số mẫu đánh giá\n",
    "    gradient_checkpointing=True,  # Bật gradient checkpointing để tiết kiệm VRAM\n",
    "    optim=\"adamw_torch\",  # Optimizer AdamW từ PyTorch\n",
    "    lr_scheduler_type=\"cosine\",  # Lịch trình learning rate kiểu cosine\n",
    "    reward_adapter=\"./saved_models/reward_model_deepseek-r1-distill-qwen\",  # Adapter reward\n",
    "    rl_base_model=\"./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\",  # Mô hình RL\n",
    "    tokenizer_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",  # Tokenizer\n",
    "    reward_model_name=\"./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\",  # Mô hình reward merged\n",
    "    log_with=None,  # Không dùng logging cụ thể\n",
    "    rl_learning_rate=2e-5,  # Learning rate cho RL\n",
    "    output_max_length=128,  # Độ dài đầu ra tối đa\n",
    "    mini_batch_size=4,  # Kích thước mini-batch\n",
    "    batch_size=128,  # Kích thước batch tổng\n",
    "    ppo_epochs=4,  # Số epoch cho PPO\n",
    "    rl_gradient_accumulation_steps=32,  # Số bước tích lũy gradient cho RL\n",
    "    adafactor=False,  # Không dùng Adafactor\n",
    "    early_stopping=True,  # Bật early stopping\n",
    "    target_kl=0.1,  # KL target cho RL\n",
    "    reward_baseline=0,  # Baseline cho reward\n",
    "    batched_gen=True,  # Tạo batch\n",
    "    save_freq=None,  # Tần suất lưu\n",
    "    output_dir=\"./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/\",  # Thư mục lưu checkpoint\n",
    "    seed=0,  # Seed cho RL\n",
    "    num_shots=4,  # Số shots cho few-shot\n",
    "    save_dir=\"results/\"  # Thư mục lưu kết quả\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Args in experiment:\")\n",
    "print(args)\n",
    "\n",
    "args.data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 33\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee62fe52f3064da18c7bccdaac082507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'input_ids', 'labels', 'attention_mask'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# DATA_PATH = args.data_path\n",
    "\n",
    "# data = load_dataset(\"json\", data_files=DATA_PATH)\n",
    "# data['train'][1]\n",
    "\n",
    "# # --- Tải tokenizer ---\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     args.model_path,\n",
    "#     add_eos_token=True,  # Thêm token kết thúc\n",
    "#     local_files_only=args.offline if hasattr(args, 'offline') else False,  # Chế độ offline\n",
    "#     trust_remote_code=True  # Cho DeepSeek\n",
    "# )\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token  # Gán pad_token\n",
    "\n",
    "\n",
    "# CUTOFF_LEN = 256  # Độ dài chuỗi tối đa\n",
    "# data = load_dataset(\"json\", data_files=DATA_PATH)  # Tải JSON dataset\n",
    "# val_set_size = int(0.1 * len(data[\"train\"]))  # Tính validation size\n",
    "# print(data)  # In thông tin dataset\n",
    "\n",
    "# # --- Tải dữ liệu huấn luyện và đánh giá ---\n",
    "# dataloader = sft_dataloader.SFTDataLoader(data, CUTOFF_LEN, val_set_size, tokenizer)  # Định dạng và tokenize\n",
    "# train_data, val_data = dataloader.load_data()  # Chia train/validation\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải mô hình từ: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b0535a9bed46c5ba2305371acc9b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b3de0b676f4218879989ba7a75603b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4924ccc6804d15bb37e43c6f066b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f713bd7dd83544f69638f45c1fd1c977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fde6b995bd4f47972ea14ea583078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 70\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c951b9648f4aa7983f8f3bff99c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baa67e617924d65ad31abb69b89e754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu hình LoRA: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', revision=None, inference_mode=True, r=16, target_modules={'v_proj', 'k_proj', 'q_proj', 'o_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n",
      "Lưu mô hình gộp tại: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "# from trl import SFTTrainer\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, set_peft_model_state_dict\n",
    "\n",
    "\n",
    "def supervised_finetune(args):\n",
    "    # --- Các hằng số huấn luyện ---\n",
    "    MICRO_BATCH_SIZE = args.per_device_train_batch_size  # Batch size mỗi GPU\n",
    "    BATCH_SIZE = args.batch_size  # Batch size tổng\n",
    "    MAX_STEPS = None  # Số bước tối đa, tính động\n",
    "    GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE  # Bước tích lũy gradient\n",
    "    EPOCHS = args.num_train_epochs  # Số epoch\n",
    "    LEARNING_RATE = 3e-4  # Tốc độ học\n",
    "    CUTOFF_LEN = 256  # Độ dài chuỗi tối đa\n",
    "    LORA_R = 16  # Rank LoRA\n",
    "    LORA_ALPHA = 32  # Hệ số scale LoRA\n",
    "    LORA_DROPOUT = 0.05  # Dropout LoRA\n",
    "    VAL_PCT = 0.1  # Tỷ lệ validation\n",
    "    TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]  # Layer áp dụng LoRA\n",
    "    DATA_PATH = args.data_path  # Đường dẫn dữ liệu\n",
    "    OUTPUT_DIR = args.output_path  # Thư mục lưu mô hình\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))  # Số GPU (DDP)\n",
    "\n",
    "\n",
    "    # --- Xử lý DDP ---\n",
    "    ddp = world_size != 1  # Kiểm tra đa GPU\n",
    "    if ddp:\n",
    "        torch.cuda.set_device(int(os.environ.get(\"LOCAL_RANK\", 0)))  # Gán GPU\n",
    "        GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size  # Chia tích lũy gradient\n",
    "\n",
    "    #==============================================================================================================================\n",
    "    print(f\"Đang tải mô hình từ: {args.model_path}\")  # In đường dẫn mô hình\n",
    "\n",
    "    # Step 3: Load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.model_path,\n",
    "        add_eos_token=True,  # Thêm token kết thúc\n",
    "        local_files_only=args.offline if hasattr(args, 'offline') else False  # Chế độ offline\n",
    "        )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Gán pad_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_path, \n",
    "        torch_dtype=torch.float16, \n",
    "        device_map=\"auto\")\n",
    "\n",
    "    # --- Tải dữ liệu ---\n",
    "    dataset = load_dataset(\"json\", data_files=DATA_PATH)  # Tải JSON dataset\n",
    "\n",
    "\n",
    "    val_set_size = int(VAL_PCT * len(dataset[\"train\"]))  # Tính validation size\n",
    "    print(dataset)  # In thông tin dataset\n",
    "\n",
    "\n",
    "    # --- Tải dữ liệu huấn luyện và đánh giá ---\n",
    "    dataloader = sft_dataloader.SFTDataLoader(dataset, CUTOFF_LEN, val_set_size, tokenizer)  # Định dạng và tokenize\n",
    "    train_data, val_data = dataloader.load_data()  # Chia train/validation\n",
    "    train_data, val_data\n",
    "\n",
    "    # Step 4: Configure LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        r=LORA_R,  # Rank LoRA\n",
    "        lora_alpha=LORA_ALPHA,  # Scale LoRA\n",
    "        target_modules=TARGET_MODULES,  # Layer LoRA\n",
    "        lora_dropout=LORA_DROPOUT,  # Dropout\n",
    "        bias=\"none\",  # Không bias\n",
    "        task_type=\"CAUSAL_LM\"  # Tác vụ ngôn ngữ\n",
    "    )\n",
    "\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "\n",
    "    # --- Tính max_steps ---\n",
    "    now_max_steps = max((len(dataset[\"train\"]) - val_set_size) // BATCH_SIZE * EPOCHS, EPOCHS)  # Số bước tối đa\n",
    "\n",
    "\n",
    "    # --- Xử lý checkpoint ---\n",
    "    if args.resume_from_supervised_checkpoint:  # Nếu có checkpoint\n",
    "        checkpoint_name = os.path.join(args.resume_from_supervised_checkpoint, \"pytorch_model.bin\")  # Đường dẫn checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            pytorch_bin_path = checkpoint_name\n",
    "            checkpoint_name = os.path.join(args.resume_from_supervised_checkpoint, \"adapter_model.bin\")  # Kiểm tra file khác\n",
    "            if os.path.exists(checkpoint_name):\n",
    "                os.rename(checkpoint_name, pytorch_bin_path)  # Đổi tên\n",
    "                warnings.warn(\"Đã đổi tên 'adapter_model.bin' thành 'pytorch_model.bin'\")\n",
    "            else:\n",
    "                args.resume_from_supervised_checkpoint = None  # Bỏ resume\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Tiếp tục từ: {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)  # Tải LoRA\n",
    "            model = set_peft_model_state_dict(model, adapters_weights)  # Áp dụng\n",
    "        else:\n",
    "            print(f\"Không tìm thấy: {checkpoint_name}\")\n",
    "        train_args_path = os.path.join(args.resume_from_supervised_checkpoint, \"trainer_state.json\")  # File trạng thái\n",
    "        if os.path.exists(train_args_path):\n",
    "            base_train_args = json.load(open(train_args_path, 'r'))\n",
    "            base_max_steps = base_train_args[\"max_steps\"]  # Số bước cũ\n",
    "            resume_scale = base_max_steps / now_max_steps\n",
    "            if base_max_steps > now_max_steps:\n",
    "                warnings.warn(f\"Thay epoch {EPOCHS} bằng {base_max_steps}\")\n",
    "                EPOCHS = None\n",
    "                MAX_STEPS = base_max_steps\n",
    "            else:\n",
    "                MAX_STEPS = now_max_steps\n",
    "    else:\n",
    "        MAX_STEPS = now_max_steps\n",
    "\n",
    "\n",
    "    # Step 5: Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,  # Directory to save results\n",
    "        per_device_train_batch_size=MICRO_BATCH_SIZE,  # Batch size GPU\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,  # Tích lũy gradient\n",
    "        warmup_steps=100,  # Bước khởi động\n",
    "        num_train_epochs=EPOCHS if EPOCHS else 1,  # Epoch\n",
    "        max_steps=MAX_STEPS,  # Số bước tối đa\n",
    "        learning_rate=LEARNING_RATE,  # Tốc độ học\n",
    "        bf16=args.bf16,  # BF16\n",
    "        fp16=not args.bf16,  # FP16\n",
    "        logging_steps=20,  # Log mỗi 20 bước\n",
    "        eval_strategy=\"steps\" if val_set_size > 0 else \"no\",  # Đánh giá\n",
    "        save_strategy=\"steps\",  # Lưu checkpoint\n",
    "        eval_steps=args.eval_steps if val_set_size > 0 else None,  # Bước đánh giá\n",
    "        save_steps=args.save_steps,  # Bước lưu\n",
    "        save_total_limit=30,  # Số checkpoint tối đa\n",
    "        load_best_model_at_end=True if val_set_size > 0 else False,  # Tải mô hình tốt\n",
    "        ddp_find_unused_parameters=False if ddp else None,  # Tối ưu DDP\n",
    "        report_to=\"wandb\" if args.wandb else [],  # Báo cáo WandB\n",
    "        optim=args.optim,  # Bộ tối ưu\n",
    "        lr_scheduler_type=args.lr_scheduler_type,  # Scheduler\n",
    "        remove_unused_columns=True,  # Xóa cột thừa\n",
    "        max_grad_norm=1.0,  # Giới hạn gradient\n",
    "    )\n",
    "\n",
    "\n",
    "    # Step 6: Initialize the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data, \n",
    "        eval_dataset=val_data,  # Small evaluation set\n",
    "        data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    # Step 7: Train the model\n",
    "    trainer.train(resume_from_checkpoint=args.resume_from_supervised_checkpoint)\n",
    "    \n",
    "    model.save_pretrained(OUTPUT_DIR) \n",
    "\n",
    "# --- Chạy huấn luyện ---\n",
    "\n",
    "supervised_finetune(args)\n",
    "\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "\n",
    "# --- Gộp adapter LoRA ---\n",
    "merge_peft_adapter(model_name=args.output_path, output_name=args.rl_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Giải phóng bộ nhớ trên GPU\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: ./datasets/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 546,304 || all params: 1,544,262,144 || trainable%: 0.0354\n",
      "train_dataset:  3\n",
      "train_dataset:  3\n",
      "eval_dataset:  3\n",
      "eval_dataset:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving last checkpoint of the model\n",
      "Cấu hình LoRA: LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', revision=None, inference_mode=True, r=4, target_modules={'q_proj', 'v_proj'}, exclude_modules=None, lora_alpha=8, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=['classifier', 'score'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n",
      "Lưu mô hình gộp tại: ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerBase,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "from predict_module import rm_dataloader\n",
    "\n",
    "def train_reward_model(args):\n",
    "    script_args = args\n",
    "    dataset_name = script_args.datasets_dir\n",
    "    print(\"dataset_name:\", dataset_name)\n",
    "    \n",
    "    output_name = script_args.reward_adapter\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_name,\n",
    "        learning_rate=script_args.reward_learning_rate,\n",
    "        per_device_train_batch_size=1,  # Giảm batch size\n",
    "        per_device_eval_batch_size=1,\n",
    "        num_train_epochs=script_args.num_train_epochs,\n",
    "        weight_decay=script_args.weight_decay,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=200,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "        gradient_accumulation_steps=16,  # Tăng gradient accumulation\n",
    "        gradient_checkpointing=False,  # Tắt gradient checkpointing\n",
    "        deepspeed=None,  # Tắt DeepSpeed để kiểm tra\n",
    "        remove_unused_columns=False,\n",
    "        label_names=[],\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=10,\n",
    "        optim=script_args.optim,\n",
    "        lr_scheduler_type=script_args.lr_scheduler_type,\n",
    "        report_to=\"none\",\n",
    "        no_cuda=False,  # Đảm bảo dùng GPU\n",
    "        bf16=True,\n",
    "    )\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(script_args.reward_base_model, trust_remote_code=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        script_args.reward_base_model,\n",
    "        num_labels=1,\n",
    "        torch_dtype=torch.bfloat16,  # Thử bfloat16\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    # # Handle pad token\n",
    "    # if tokenizer.pad_token is None:\n",
    "    #     tokenizer.pad_token = tokenizer.eos_token\n",
    "    #     model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    # else:\n",
    "    #     model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Set device\n",
    "    # device_map = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # print(\"device_map:\", device_map)\n",
    "    # model = model.to(device_map)  # Chuyển thủ công\n",
    "    \n",
    "    # LoRA config\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=4,  # Giảm r\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    num_proc = 1\n",
    "    reward_dataloder = rm_dataloader.RewardDataLoader(dataset_name, script_args.train_subset, script_args.eval_subset, num_proc, tokenizer)\n",
    "    train_dataset, eval_dataset = reward_dataloder.load_data()\n",
    "    \n",
    "    @dataclass\n",
    "    class RewardDataCollatorWithPadding:\n",
    "        tokenizer: PreTrainedTokenizerBase\n",
    "        padding: Union[bool, str, PaddingStrategy] = True\n",
    "        max_length: Optional[int] = None\n",
    "        pad_to_multiple_of: Optional[int] = None\n",
    "        return_tensors: str = \"pt\"\n",
    "\n",
    "        def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "            features_j = []\n",
    "            features_k = []\n",
    "            for feature in features:\n",
    "                features_j.append(\n",
    "                    {\n",
    "                        \"input_ids\": feature[\"input_ids_j\"],\n",
    "                        \"attention_mask\": feature[\"attention_mask_j\"],\n",
    "                    }\n",
    "                )\n",
    "                features_k.append(\n",
    "                    {\n",
    "                        \"input_ids\": feature[\"input_ids_k\"],\n",
    "                        \"attention_mask\": feature[\"attention_mask_k\"],\n",
    "                    }\n",
    "                )\n",
    "            batch_j = self.tokenizer.pad(\n",
    "                features_j,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "                return_tensors=self.return_tensors,\n",
    "            )\n",
    "            batch_k = self.tokenizer.pad(\n",
    "                features_k,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "                return_tensors=self.return_tensors,\n",
    "            )\n",
    "            batch = {\n",
    "                \"input_ids_j\": batch_j[\"input_ids\"],\n",
    "                \"attention_mask_j\": batch_j[\"attention_mask\"].to(dtype=torch.bfloat16),\n",
    "                \"input_ids_k\": batch_k[\"input_ids\"],\n",
    "                \"attention_mask_k\": batch_k[\"attention_mask\"].to(dtype=torch.bfloat16),\n",
    "                \"return_loss\": True,\n",
    "            }\n",
    "            return batch\n",
    "    \n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, _ = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=0)\n",
    "        labels = np.zeros(predictions.shape)\n",
    "        return accuracy.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    class RewardTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "            rewards_j = model(\n",
    "                input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n",
    "            rewards_k = model(\n",
    "                input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n",
    "            loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()\n",
    "            if return_outputs:\n",
    "                return loss, {\"rewards_j\": rewards_j, \"rewards_k\": rewards_k}\n",
    "            return loss\n",
    "    \n",
    "    trainer = RewardTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=RewardDataCollatorWithPadding(\n",
    "            tokenizer=tokenizer, max_length=512, pad_to_multiple_of=8),\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = True\n",
    "    trainer.train(script_args.resume_from_reward_checkpoint)\n",
    "    \n",
    "    print(\"Saving last checkpoint of the model\")\n",
    "    model.save_pretrained(output_name)\n",
    "\n",
    "train_reward_model(args)\n",
    "\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "merge_peft_adapter(model_name=args.reward_adapter, output_name=args.reward_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giải phóng bộ nhớ trên GPU\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# from transformers import DataCollatorWithPadding, AutoTokenizer\n",
    "\n",
    "\n",
    "# def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "#     \"\"\"\n",
    "#     Tạo dataset cho huấn luyện PPO.\n",
    "    \n",
    "#     Args:\n",
    "#         tokenizer: Tokenizer để mã hóa văn bản.\n",
    "#         dataset_name: Tên hoặc đường dẫn dataset.\n",
    "#         input_min_text_length: Độ dài tối thiểu của câu hỏi.\n",
    "#         input_max_text_length: Độ dài tối đa của câu hỏi.\n",
    "    \n",
    "#     Returns:\n",
    "#         Dataset đã được xử lý với các cột query và input_ids.\n",
    "#     \"\"\"\n",
    "#     ds = load_dataset(dataset_name, split=\"train\")\n",
    "#     original_columns = ds.column_names\n",
    "#     def preprocess_function(examples):\n",
    "#         new_examples = {\n",
    "#             \"query\": [],\n",
    "#             \"input_ids\": [],\n",
    "#         }\n",
    "#         # Giả định dataset có cột 'user_input' hoặc 'question'\n",
    "#         input_key = \"user_input\" if \"user_input\" in examples else \"question\"\n",
    "#         for question in examples[input_key]:\n",
    "#             query = \"Question: \" + question + \"\\n\\nAnswer: \"\n",
    "#             tokenized_question = tokenizer(\n",
    "#                 query,\n",
    "#                 truncation=True,\n",
    "#                 max_length=512,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             )\n",
    "#             new_examples[\"query\"].append(query)\n",
    "#             new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"].squeeze(0))\n",
    "#         return new_examples\n",
    "\n",
    "#     ds = ds.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         num_proc=1,\n",
    "#         remove_columns=original_columns,\n",
    "#     )\n",
    "#     ds.set_format(type=\"torch\")\n",
    "#     return ds\n",
    "\n",
    "#     # Tạo dataset\n",
    "#     dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "\n",
    "# dataset_name = args.datasets_dir\n",
    "\n",
    "# ds = load_dataset(dataset_name, split=\"train\")\n",
    "# ds\n",
    "\n",
    "# tokenizer_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# # Tải tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "    \n",
    "# dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "\n",
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_model_name: ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged\n",
      "dataset_name: ./datasets/\n",
      "model_name: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\n",
      "train_dataset size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: LlamaTokenizerFast\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e2f666cc734bdf8d357ed6c80019cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 64 samples\n",
      "Finetune model: ./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged <class 'trl.models.modeling_value_head.AutoModelForCausalLMWithValueHead'>\n",
      "Dataset({\n",
      "    features: ['query', 'input_ids'],\n",
      "    num_rows: 64\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at ./saved_models/reward_model_deepseek-r1-distill-qwen-adapter-merged and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "0it [00:00, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/.venv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "10it [05:20, 32.65s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "16it [08:50, 33.17s/it]\n",
      "/root/.venv/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1431: UserWarning: Cannot retrieve user information assuming you are running in offline mode.\n",
      "  warnings.warn(\"Cannot retrieve user information assuming you are running in offline mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final checkpoint saved at: ./saved_models/tuning_deepseek_r1_distill_qwen_checkpoints/step_saved\n",
      "Cấu hình LoRA: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged', revision=None, inference_mode=True, r=8, target_modules={'q_proj', 'v_proj', 'o_proj', 'k_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu mô hình gộp tại: ./saved_models/sep_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3391: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb569fd29cd49df8db2c6e5aac57771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving checkpoint shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import Adafactor, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, AutoModelForCausalLM, DataCollatorWithPadding\n",
    "from transformers import GenerationConfig, pipeline\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "from trl.core import LengthSampler\n",
    "from trl import create_reference_model\n",
    "import os\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def tuning_lm_with_rl(args):\n",
    "    # Khởi tạo script_args từ args\n",
    "    script_args = args\n",
    "    reward_model_name = script_args.reward_model_name\n",
    "    print(\"reward_model_name:\", reward_model_name)\n",
    "\n",
    "    # Đường dẫn dataset\n",
    "    dataset_name = script_args.datasets_dir\n",
    "    print(\"dataset_name:\", dataset_name)\n",
    "\n",
    "    # Cấu hình PPO\n",
    "    config = PPOConfig(\n",
    "        learning_rate=script_args.rl_learning_rate,\n",
    "        # batch_size=script_args.batch_size,\n",
    "        batch_size=4,\n",
    "        # mini_batch_size=script_args.mini_batch_size,\n",
    "        mini_batch_size=2,\n",
    "        # gradient_accumulation_steps=script_args.rl_gradient_accumulation_steps,\n",
    "        gradient_accumulation_steps=1,\n",
    "        ppo_epochs=script_args.ppo_epochs,  \n",
    "        seed=script_args.seed,\n",
    "    )\n",
    "\n",
    "    # Tên mô hình gốc\n",
    "    model_name = script_args.rl_base_model\n",
    "    print(\"model_name:\", model_name)\n",
    "\n",
    "    # Tải dataset\n",
    "    train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    print(\"train_dataset size:\", len(train_dataset))\n",
    "\n",
    "    # Cấu hình tham số cho sentiment pipeline\n",
    "    sent_kwargs = {\n",
    "        \"return_all_scores\": True,\n",
    "        \"function_to_apply\": \"none\",\n",
    "        \"batch_size\": 1,\n",
    "        \"truncation\": True\n",
    "    }\n",
    "\n",
    "    # Tải tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(script_args.tokenizer_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"Tokenizer loaded:\", tokenizer.__class__.__name__)\n",
    "\n",
    "    def build_dataset(tokenizer, dataset_name, input_min_text_length=2, input_max_text_length=8):\n",
    "        \"\"\"\n",
    "        Tạo dataset cho huấn luyện PPO.\n",
    "        \n",
    "        Args:\n",
    "            tokenizer: Tokenizer để mã hóa văn bản.\n",
    "            dataset_name: Tên hoặc đường dẫn dataset.\n",
    "            input_min_text_length: Độ dài tối thiểu của câu hỏi.\n",
    "            input_max_text_length: Độ dài tối đa của câu hỏi.\n",
    "        \n",
    "        Returns:\n",
    "            Dataset đã được xử lý với các cột query và input_ids.\n",
    "        \"\"\"\n",
    "        ds = load_dataset(dataset_name, split=\"train\")\n",
    "        # Giả sử dataset của bạn tên là `ds`, hiện có 6 dòng\n",
    "        repeat_factor = 64 // len(ds) + 1  # Lặp đủ số lần để vượt 64\n",
    "\n",
    "        # Lặp lại nhiều lần rồi cắt còn đúng 64\n",
    "        ds = concatenate_datasets([ds] * repeat_factor)\n",
    "        ds = ds.select(range(64))  # Lấy đúng 64 dòng\n",
    "        original_columns = ds.column_names\n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            new_examples = {\n",
    "                \"query\": [],\n",
    "                \"input_ids\": [],\n",
    "            }\n",
    "            # Giả định dataset có cột 'user_input' hoặc 'question'\n",
    "            input_key = \"user_input\" if \"user_input\" in examples else \"question\"\n",
    "            for question in examples[input_key]:\n",
    "                query = \"Question: \" + question + \"\\n\\nAnswer: \"\n",
    "                tokenized_question = tokenizer(\n",
    "                    query,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                new_examples[\"query\"].append(query)\n",
    "                new_examples[\"input_ids\"].append(tokenized_question[\"input_ids\"].squeeze(0))\n",
    "            return new_examples\n",
    "\n",
    "        ds = ds.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            num_proc=1,\n",
    "            remove_columns=original_columns,\n",
    "        )\n",
    "        ds.set_format(type=\"torch\")\n",
    "        return ds\n",
    "\n",
    "    # Tạo dataset\n",
    "    dataset = build_dataset(tokenizer, dataset_name=dataset_name)\n",
    "    print(\"Dataset created with\", len(dataset), \"samples\")\n",
    "\n",
    "    def collator(data):\n",
    "        \"\"\"\n",
    "        Collator để xử lý batch dữ liệu.\n",
    "        \"\"\"\n",
    "        return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "    # def collator(data):\n",
    "    #     \"\"\"\n",
    "    #     Custom collator cho PPOTrainer.\n",
    "    #     Dữ liệu đầu vào là list[dict], mỗi dict chứa:\n",
    "    #         - \"query\": str\n",
    "    #         - \"input_ids\": Tensor (1D)\n",
    "    #     \"\"\"\n",
    "    #     input_ids = [item[\"input_ids\"] for item in data]\n",
    "    #     queries = [item[\"query\"] for item in data]\n",
    "\n",
    "    #     # Pad input_ids thủ công nếu cần\n",
    "    #     input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    #     return {\n",
    "    #         \"input_ids\": input_ids,\n",
    "    #         \"query\": queries,\n",
    "    #     }\n",
    "\n",
    "    # Đặt seed để đảm bảo tính tái lập\n",
    "    torch.manual_seed(config.seed)\n",
    "\n",
    "    # Cấu hình LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "    )\n",
    "\n",
    "    # Tải mô hình chính với value head\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,  # Đồng bộ với reward model\n",
    "        peft_config=lora_config,\n",
    "    )\n",
    "\n",
    "    # Gán thủ công base_model_prefix để tránh lỗi\n",
    "    model.base_model_prefix = \"model\"  # hoặc \"transformer\", tùy thuộc vào tên trong mô hình gốc\n",
    "    # Gán generation_config để tránh lỗi AttributeError\n",
    "    model.generation_config = GenerationConfig.from_pretrained(\n",
    "        \"./saved_models/lora-DeepSeek-R1-Distill-Qwen-adapter-merged\"\n",
    "    )\n",
    "    # model.config.return_dict = True\n",
    "\n",
    "    # try:\n",
    "    #     model.base_model.model.config.return_dict = True\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "    # # Tải mô hình giá trị (value model) với value head\n",
    "    # value_model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     model_name,\n",
    "    #     torch_dtype=torch.bfloat16,\n",
    "    #     trust_remote_code=True,\n",
    "    # )\n",
    "    # # value_model = get_peft_model(value_model, lora_config)\n",
    "    # def force_return_dict_recursively(model):\n",
    "    #     \"\"\"\n",
    "    #     Recursively patch forward function of all relevant submodules to enforce return_dict=True.\n",
    "    #     \"\"\"\n",
    "    #     if hasattr(model, 'forward'):\n",
    "    #         original_forward = model.forward\n",
    "\n",
    "    #         def patched_forward(*args, **kwargs):\n",
    "    #             kwargs[\"return_dict\"] = True\n",
    "    #             return original_forward(*args, **kwargs)\n",
    "\n",
    "    #         model.forward = patched_forward\n",
    "\n",
    "    #     # Patch model.base_model.model nếu có\n",
    "    #     if hasattr(model, \"base_model\") and hasattr(model.base_model, \"model\"):\n",
    "    #         force_return_dict_recursively(model.base_model.model)\n",
    "\n",
    "    #     return model\n",
    "\n",
    "    # # Sau khi load:\n",
    "    # model = force_return_dict_recursively(model)\n",
    "    # value_model = force_return_dict_recursively(value_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Tạo generation_config nếu không có\n",
    "    if not hasattr(model, \"generation_config\"):\n",
    "        model.generation_config = GenerationConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    print(\"Finetune model:\", model_name, type(model))\n",
    "\n",
    "    # # Tải reward model từ checkpoint\n",
    "    # reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    #     reward_model_name,\n",
    "    #     torch_dtype=torch.bfloat16,\n",
    "    #     trust_remote_code=True,\n",
    "    # )\n",
    "    # reward_model_config = AutoConfig.from_pretrained(reward_model_name, trust_remote_code=True)\n",
    "    # print(\"Reward model:\", type(reward_model))\n",
    "\n",
    "    # Tạo optimizer (nếu dùng Adafactor)\n",
    "    optimizer = None\n",
    "    if script_args.adafactor:\n",
    "        optimizer = Adafactor(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            scale_parameter=False,\n",
    "            relative_step=False,\n",
    "            warmup_init=False,\n",
    "            lr=config.learning_rate,\n",
    "        )\n",
    "\n",
    "    # Khởi tạo PPOTrainer\n",
    "    print(dataset)\n",
    "    ppo_trainer = PPOTrainer(\n",
    "        config=config,  # Sử dụng args thay vì config\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,  \n",
    "        # reward_model=reward_model,\n",
    "        # ref_model = None,\n",
    "        # value_model=value_model,\n",
    "        dataset=dataset,\n",
    "        data_collator=collator,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    \n",
    "    # ppo_trainer.train()\n",
    "\n",
    "    # Xác định thiết bị\n",
    "    device = ppo_trainer.accelerator.device\n",
    "    if ppo_trainer.accelerator.num_processes == 1:\n",
    "        device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Tạo sentiment pipeline\n",
    "    sentiment_pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=reward_model_name,\n",
    "        device_map=\"auto\",\n",
    "        # config=reward_model_config,\n",
    "        tokenizer=tokenizer,\n",
    "        # device=device,\n",
    "    )\n",
    "\n",
    "    # Cấu hình tham số sinh văn bản\n",
    "    generation_kwargs = {\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 1.0,\n",
    "        \"do_sample\": True,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    output_min_length = 32\n",
    "    output_max_length = script_args.output_max_length\n",
    "    output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "    # Vòng lặp huấn luyện PPO\n",
    "    for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "        question_tensors = batch[\"input_ids\"]\n",
    "\n",
    "        # Sinh phản hồi\n",
    "        response_tensors = ppo_trainer.generate(\n",
    "            question_tensors,\n",
    "            return_prompt=False,\n",
    "            length_sampler=output_length_sampler,\n",
    "            **generation_kwargs,\n",
    "        )\n",
    "        batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "        # Tính điểm thưởng từ reward model\n",
    "        texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "        pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "        rewards = [torch.tensor(output[0][\"score\"] - script_args.reward_baseline) for output in pipe_outputs]\n",
    "\n",
    "        # Thực hiện bước PPO\n",
    "        stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "        ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "        # Lưu checkpoint định kỳ\n",
    "        if script_args.save_freq and epoch and epoch % script_args.save_freq == 0:\n",
    "            save_dir = os.path.join(script_args.output_dir, f\"step_{epoch}\")\n",
    "            ppo_trainer.save_pretrained(save_dir)\n",
    "            print(f\"Saved checkpoint at: {save_dir}\")\n",
    "\n",
    "    # Lưu checkpoint cuối cùng\n",
    "    final_save_dir = os.path.join(script_args.output_dir, \"step_saved\")\n",
    "    ppo_trainer.save_pretrained(final_save_dir)\n",
    "    print(f\"Final checkpoint saved at: {final_save_dir}\")\n",
    "\n",
    "# Chạy hàm\n",
    "tuning_lm_with_rl(args)\n",
    "\n",
    "# # Gộp adapter LoRA\n",
    "from predict_module.merge_peft_adapter import merge_peft_adapter\n",
    "merge_peft_adapter(\n",
    "    model_name=os.path.join(args.output_dir, \"step_saved\"),\n",
    "    output_name=\"./saved_models/sep_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SUMMARIZE Tập Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from explain_module.agents import PredictReflectAgent\n",
    "# from data_load.dataloader import DataLoader\n",
    "\n",
    "# dataloader = DataLoader(args)\n",
    "\n",
    "# print(\"Loading Test Agents...\")\n",
    "# data_test = dataloader.load(flag=\"test\")\n",
    "\n",
    "# # Lưu DataFrame vào tệp CSV\n",
    "# path = args.llm_summarize+\"_data_test.csv\"\n",
    "# data_test.to_csv(path, index=False)  # index=False để không lưu chỉ số dòng\n",
    "# print(f\"DataFrame đã được lưu vào '{path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thêm Technical Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import pandas_ta as ta  # Sử dụng pandas_ta vì dễ cài đặt và tích hợp với pandas\n",
    "# import numpy as np\n",
    "\n",
    "# def format_technical_indicators(row):\n",
    "#     \"\"\"\n",
    "#     Chuyển đổi một dòng của DataFrame thành văn bản, bỏ qua giá trị NaN.\n",
    "\n",
    "#     Args:\n",
    "#         row (pd.Series): Một dòng của DataFrame chứa các chỉ số kỹ thuật.\n",
    "\n",
    "#     Returns:\n",
    "#         str: Văn bản chứa chỉ số kỹ thuật, mỗi dòng cách nhau bởi '\\n'.\n",
    "#     \"\"\"\n",
    "#     lines = []\n",
    "    \n",
    "#     for col, value in row.items():\n",
    "#         if pd.notna(value):  # Bỏ qua nếu giá trị là NaN\n",
    "#             lines.append(f\"{col}: {value:,}\")  # Định dạng số với dấu phẩy\n",
    "    \n",
    "#     return \"\\n\".join(lines)  # Kết hợp các dòng thành văn bản\n",
    "\n",
    "\n",
    "# # Đọc file CSV vào DataFrame\n",
    "# data = pd.read_csv(\"data_test.csv\")\n",
    "\n",
    "\n",
    "# def add_technical_indicator(data):\n",
    "#     # Lấy danh sách các giá trị duy nhất của cột \"ticker\"\n",
    "#     unique_tickers = data[\"ticker\"].unique()\n",
    "#     unique_tickers\n",
    "\n",
    "#     technical_indicator_dir = \"data/sample_price/technical_indicator/\"\n",
    "#     # DataFrame để lưu kết quả cuối cùng\n",
    "#     final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#     for file_name in unique_tickers:\n",
    "\n",
    "#         technical_indicator_path = os.path.join(technical_indicator_dir, file_name + \".csv\")\n",
    "\n",
    "#         df_technical_indicator = pd.read_csv(technical_indicator_path)\n",
    "\n",
    "#         # Loại bỏ cột 'Date' để chỉ giữ các chỉ báo kỹ thuật\n",
    "#         df_technical_indicator[\"technical_indicator\"] = df_technical_indicator.drop(columns=[\"Date\"]).apply(format_technical_indicators, axis=1)\n",
    "\n",
    "#         # Thêm cột \"ticker\" với giá trị file_name\n",
    "#         df_technical_indicator[\"ticker\"] = file_name\n",
    "\n",
    "#         # Hiển thị kết quả  \n",
    "#         df_technical_indicator = df_technical_indicator[[\"ticker\", \"Date\", \"technical_indicator\"]].rename(columns={\"Date\": \"date\"})\n",
    "#         # Merge theo 2 cột \"ticker\" và \"Date\"\n",
    "#         merged_df = pd.merge(data, df_technical_indicator, on=[\"ticker\", \"date\"], how=\"inner\")\n",
    "\n",
    "#         # Cộng dồn kết quả\n",
    "#         final_df = pd.concat([final_df, merged_df], ignore_index=True)\n",
    "\n",
    "#     return final_df\n",
    "\n",
    "    \n",
    "\n",
    "# data = add_technical_indicator(data)\n",
    "# data\n",
    "\n",
    "# data.to_csv(\"data_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHẠY TẬP TEST\n",
    "*** chú ý: Kích thước tập Test chưa được chạy toàn bộ (data = data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>summary</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>technical_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021-12-05\\nAmazon (AMZN) is making its own co...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>SMA_5: 174.01\\nEMA_5: 173.63\\nMACD: 0.05\\nMACD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021-12-29\\n- Amazon's stock symbol is $AMZN.\\...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>SMA_5: 169.13\\nEMA_5: 169.2\\nMACD: -1.23\\nMACD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                                            summary    target  \\\n",
       "0   AMZN  2021-12-05\\nAmazon (AMZN) is making its own co...  Negative   \n",
       "1   AMZN  2021-12-29\\n- Amazon's stock symbol is $AMZN.\\...  Positive   \n",
       "\n",
       "         date                                technical_indicator  \n",
       "0  2021-12-10  SMA_5: 174.01\\nEMA_5: 173.63\\nMACD: 0.05\\nMACD...  \n",
       "1  2022-01-03  SMA_5: 169.13\\nEMA_5: 169.2\\nMACD: -1.23\\nMACD...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "\n",
    "# Đọc tệp CSV\n",
    "data = pd.read_csv(args.llm_summarize+\"_data_test.csv\")\n",
    "data = data[:2]\n",
    "data\n",
    "\n",
    "\n",
    "# agent_cls = PredictReflectAgent\n",
    "# test_agents = [agent_cls(row['ticker'], row['summary'], row['target']) for _, row in data.iterrows()]\n",
    "# print(\"Loaded Test Agents.\")\n",
    "# test_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers import GenerationConfig, pipeline\n",
    "\n",
    "\n",
    "def test(args):\n",
    "\n",
    "    # Đọc tệp CSV\n",
    "    data = pd.read_csv(args.llm_summarize+\"_data_test.csv\")\n",
    "    data = data[:2] # Giảm kích thước tập Test để chạy nhanh hơn\n",
    "\n",
    "\n",
    "    #==========================================================================\n",
    "    # print(\"Loading Test Agents...\")\n",
    "    # data = self.dataloader.load(flag=\"test\")\n",
    "    # print(\"Test data loaded with columns:\", data.columns.tolist())\n",
    "    # print(\"Number of test samples:\", len(data))\n",
    "    #==========================================================================\n",
    "\n",
    "    agent_cls = PredictReflectAgent\n",
    "    test_agents = [agent_cls(row['ticker'], row['summary'], row['target'], row['technical_indicator'], '') for _, row in data.iterrows()]\n",
    "    print(\"Loaded Test Agents:\", len(test_agents))\n",
    "\n",
    "\n",
    "    tokenizer_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        \"./saved_models/sep_model\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    reward_model = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=args.reward_model_name,\n",
    "        device_map=\"auto\",\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    for agent in test_agents:\n",
    "        agent.run_n_shots(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            reward_model=reward_model,\n",
    "            num_shots=args.num_shots\n",
    "        )\n",
    "\n",
    "    correct, incorrect = summarize_trial(test_agents)\n",
    "    print(f'Finished evaluation, Correct: {len(correct)}, Incorrect: {len(incorrect)}')\n",
    "\n",
    "    save_results(test_agents, args.save_dir)\n",
    "    print(f\"kết quả được lưu vào fie {args.save_dir}\")\n",
    "\n",
    "test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Đọc Kết Quả và tính Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\nExplanation: Amazon's strong fourth...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Amazon's strong fourth-quarter performance, dr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\nExplanation: Amazon's strong Q3 perf...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Amazon's strong Q3 performance, strong cash re...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  Given a list of facts and a set of technical i...   \n",
       "1  Given a list of facts and a set of technical i...   \n",
       "\n",
       "                                            Response      Trend  \\\n",
       "0   Positive\\nExplanation: Amazon's strong fourth...   Positive   \n",
       "1  Positive\\nExplanation: Amazon's strong Q3 perf...   Positive   \n",
       "\n",
       "                                         Explanation    Target  \n",
       "0  Amazon's strong fourth-quarter performance, dr...  Negative  \n",
       "1  Amazon's strong Q3 performance, strong cash re...  Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.read_csv(\"results/results.csv\")\n",
    "df_result\n",
    "\n",
    "# Tách cột 'Response' thành hai cột mới\n",
    "df_result[['Trend', 'Explanation']] = df_result['Response'].str.split(r'\\nExplanation:\\s*', expand=True)\n",
    "df_result # Đặt lại thứ tự cột\n",
    "df_result = df_result[['Prompt', 'Response', 'Trend', 'Explanation', 'Target']]\n",
    "df_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính Accuracy và MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n",
      "MCC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "y_pred = df_result[\"Trend\"]\n",
    "y_true = df_result[\"Target\"]\n",
    "\n",
    "# Tính accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Tính MCC\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\n\\nExplanation: Despite mixed market ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Despite mixed market performance and ongoing d...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Negative\\n\\nExplanation: Despite some technica...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Despite some technical indicators suggesting a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\n\\nExplanation: The technical indicat...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The technical indicators show a mixed signal w...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\n\\nExplanation: Despite some negative...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Despite some negative sentiment in the tech se...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Neutral\\n\\nExplanation: The technical indicato...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>The technical indicators suggest that the stoc...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Negative\\n\\nExplanation: Despite relatively ne...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Despite relatively neutral technical indicator...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Negative\\n\\nExplanation: Despite having a rela...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Despite having a relatively stable SMA and EMA...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Negative\\n\\nExplanation: Despite having a slig...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Despite having a slightly higher SMA and EMA, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Negative\\n\\nExplanation: Despite some positive...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Despite some positive factors like an increase...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Given a list of facts and a set of technical i...</td>\n",
       "      <td>Positive\\n\\nExplanation: Despite some mixed si...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Despite some mixed signals from technical indi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Prompt  \\\n",
       "0    Given a list of facts and a set of technical i...   \n",
       "1    Given a list of facts and a set of technical i...   \n",
       "2    Given a list of facts and a set of technical i...   \n",
       "3    Given a list of facts and a set of technical i...   \n",
       "4    Given a list of facts and a set of technical i...   \n",
       "..                                                 ...   \n",
       "163  Given a list of facts and a set of technical i...   \n",
       "164  Given a list of facts and a set of technical i...   \n",
       "165  Given a list of facts and a set of technical i...   \n",
       "166  Given a list of facts and a set of technical i...   \n",
       "167  Given a list of facts and a set of technical i...   \n",
       "\n",
       "                                              Response     Trend  \\\n",
       "0    Positive\\n\\nExplanation: Despite mixed market ...  Positive   \n",
       "1    Negative\\n\\nExplanation: Despite some technica...  Negative   \n",
       "2    Positive\\n\\nExplanation: The technical indicat...  Positive   \n",
       "3    Positive\\n\\nExplanation: Despite some negative...  Positive   \n",
       "4    Neutral\\n\\nExplanation: The technical indicato...   Neutral   \n",
       "..                                                 ...       ...   \n",
       "163  Negative\\n\\nExplanation: Despite relatively ne...  Negative   \n",
       "164  Negative\\n\\nExplanation: Despite having a rela...  Negative   \n",
       "165  Negative\\n\\nExplanation: Despite having a slig...  Negative   \n",
       "166  Negative\\n\\nExplanation: Despite some positive...  Negative   \n",
       "167  Positive\\n\\nExplanation: Despite some mixed si...  Positive   \n",
       "\n",
       "                                           Explanation    Target  \n",
       "0    Despite mixed market performance and ongoing d...  Negative  \n",
       "1    Despite some technical indicators suggesting a...  Positive  \n",
       "2    The technical indicators show a mixed signal w...  Negative  \n",
       "3    Despite some negative sentiment in the tech se...  Positive  \n",
       "4    The technical indicators suggest that the stoc...  Negative  \n",
       "..                                                 ...       ...  \n",
       "163  Despite relatively neutral technical indicator...  Negative  \n",
       "164  Despite having a relatively stable SMA and EMA...  Negative  \n",
       "165  Despite having a slightly higher SMA and EMA, ...  Positive  \n",
       "166  Despite some positive factors like an increase...  Negative  \n",
       "167  Despite some mixed signals from technical indi...  Negative  \n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sep-main-update\\result_chatgpt\\TEST_OpenAILLM_top1_stock_technical_indicator_test_1.jsonresults.csv\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Thư mục chứa các file kết quả CSV\n",
    "folder = \"./result_chatgpt\"\n",
    "\n",
    "# Tạo danh sách file cần ghép\n",
    "csv_files = [\n",
    "    os.path.join(folder, f\"TEST_OpenAILLM_top1_stock_technical_indicator_test_{i}.jsonresults.csv\")\n",
    "    for i in range(1, 12)  # nếu bạn có 11 phần\n",
    "]\n",
    "\n",
    "# Đọc và ghép tất cả các file CSV\n",
    "df_all = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "\n",
    "# Hiển thị vài dòng đầu\n",
    "df_result = df_all\n",
    "# df_result\n",
    "\n",
    "# Tách cột 'Response' thành hai cột mới\n",
    "# Tách trend (Positive/Negative) ở dòng đầu\n",
    "df_result['Trend'] = df_result['Response'].str.split(r'\\nExplanation:\\s*').str[0].str.strip()\n",
    "\n",
    "# Tách Explanation từ '\\nExplanation:' đến trước '\\n' kế tiếp (nếu có)\n",
    "df_result['Explanation'] = df_result['Response'].str.extract(r'\\nExplanation:\\s*(.*?)(?:\\n|$)', expand=False)\n",
    "df_result # Đặt lại thứ tự cột\n",
    "df_result = df_result[['Prompt', 'Response', 'Trend', 'Explanation', 'Target']]\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5238\n",
      "MCC: 0.0801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "y_pred = df_result[\"Trend\"]\n",
    "y_true = df_result[\"Target\"]\n",
    "\n",
    "# Tính accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Tính MCC\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
