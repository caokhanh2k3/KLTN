{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.26.4\n",
    "# !pip install openai==1.63.2\n",
    "# !pip install tenacity==8.2.3\n",
    "# !pip install tiktoken==0.6.0\n",
    "# !pip install transformers==4.34.1\n",
    "# !pip install pandas==2.2.0\n",
    "# !pip install scikit-learn==1.4.0\n",
    "# !pip install torch\n",
    "# !pip install bitsandbytes==0.42.0\n",
    "# !pip install datasets==2.14.7\n",
    "# !pip install sentencepiece\n",
    "# !pip install peft==0.6.2\n",
    "# !pip install evaluate==0.4.1\n",
    "# !pip install trl==0.7.1\n",
    "# !pip install protobuf==4.25.2\n",
    "# !pip install python-dotenv\n",
    "# !pip install pandas_ta\n",
    "# !pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch==2.2.0+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas_ta as ta  # Sử dụng pandas_ta vì dễ cài đặt và tích hợp với pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_technical_indicators(row):\n",
    "    \"\"\"\n",
    "    Chuyển đổi một dòng của DataFrame thành văn bản, bỏ qua giá trị NaN.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Một dòng của DataFrame chứa các chỉ số kỹ thuật.\n",
    "\n",
    "    Returns:\n",
    "        str: Văn bản chứa chỉ số kỹ thuật, mỗi dòng cách nhau bởi '\\n'.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        if pd.notna(value):  # Bỏ qua nếu giá trị là NaN\n",
    "            lines.append(f\"{col}: {value:,}\")  # Định dạng số với dấu phẩy\n",
    "    \n",
    "    return \"\\n\".join(lines)  # Kết hợp các dòng thành văn bản\n",
    "\n",
    "\n",
    "# Đọc file CSV vào DataFrame\n",
    "data = pd.read_csv(\"data_sample2.csv\")\n",
    "\n",
    "\n",
    "def add_technical_indicator(data):\n",
    "    # Lấy danh sách các giá trị duy nhất của cột \"ticker\"\n",
    "    unique_tickers = data[\"ticker\"].unique()\n",
    "    unique_tickers\n",
    "\n",
    "    technical_indicator_dir = \"data/sample_price/technical_indicator/\"\n",
    "    # DataFrame để lưu kết quả cuối cùng\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for file_name in unique_tickers:\n",
    "\n",
    "        technical_indicator_path = os.path.join(technical_indicator_dir, file_name + \".csv\")\n",
    "\n",
    "        df_technical_indicator = pd.read_csv(technical_indicator_path)\n",
    "\n",
    "        # Loại bỏ cột 'Date' để chỉ giữ các chỉ báo kỹ thuật\n",
    "        df_technical_indicator[\"technical_indicator\"] = df_technical_indicator.drop(columns=[\"Date\"]).apply(format_technical_indicators, axis=1)\n",
    "\n",
    "        # Thêm cột \"ticker\" với giá trị file_name\n",
    "        df_technical_indicator[\"ticker\"] = file_name\n",
    "\n",
    "        # Hiển thị kết quả  \n",
    "        df_technical_indicator = df_technical_indicator[[\"ticker\", \"Date\", \"technical_indicator\"]].rename(columns={\"Date\": \"date\"})\n",
    "        # Merge theo 2 cột \"ticker\" và \"Date\"\n",
    "        merged_df = pd.merge(data, df_technical_indicator, on=[\"ticker\", \"date\"], how=\"inner\")\n",
    "\n",
    "        # Cộng dồn kết quả\n",
    "        final_df = pd.concat([final_df, merged_df], ignore_index=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "    \n",
    "\n",
    "data = add_technical_indicator(data)\n",
    "data\n",
    "\n",
    "data.to_csv(\"data_sample2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang mở: AAPL.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/AAPL.csv\n",
      "Đang mở: ABBV.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/ABBV.csv\n",
      "Đang mở: AEP.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/AEP.csv\n",
      "Đang mở: AMT.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/AMT.csv\n",
      "Đang mở: AMZN.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/AMZN.csv\n",
      "Đang mở: APD.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/APD.csv\n",
      "Đang mở: AVGO.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/AVGO.csv\n",
      "Đang mở: BABA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/BABA.csv\n",
      "Đang mở: BAC.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/BAC.csv\n",
      "Đang mở: BHP.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/BHP.csv\n",
      "Đang mở: BRK-A.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/BRK-A.csv\n",
      "Đang mở: CAT.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/CAT.csv\n",
      "Đang mở: CCI.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/CCI.csv\n",
      "Đang mở: CMCSA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/CMCSA.csv\n",
      "Đang mở: COP.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/COP.csv\n",
      "Đang mở: COST.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/COST.csv\n",
      "Đang mở: CVX.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/CVX.csv\n",
      "Đang mở: D.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/D.csv\n",
      "Đang mở: DIS.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/DIS.csv\n",
      "Đang mở: DUK.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/DUK.csv\n",
      "Đang mở: EQIX.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/EQIX.csv\n",
      "Đang mở: GOOG.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/GOOG.csv\n",
      "Đang mở: HD.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/HD.csv\n",
      "Đang mở: HON.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/HON.csv\n",
      "Đang mở: JNJ.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/JNJ.csv\n",
      "Đang mở: JPM.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/JPM.csv\n",
      "Đang mở: KO.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/KO.csv\n",
      "Đang mở: LLY.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/LLY.csv\n",
      "Đang mở: LMT.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/LMT.csv\n",
      "Đang mở: MA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/MA.csv\n",
      "Đang mở: META.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/META.csv\n",
      "Đang mở: MSFT.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/MSFT.csv\n",
      "Đang mở: NEE.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/NEE.csv\n",
      "Đang mở: NVDA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/NVDA.csv\n",
      "Đang mở: PEP.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/PEP.csv\n",
      "Đang mở: PFE.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/PFE.csv\n",
      "Đang mở: PG.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/PG.csv\n",
      "Đang mở: PLD.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/PLD.csv\n",
      "Đang mở: PSA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/PSA.csv\n",
      "Đang mở: RIO.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/RIO.csv\n",
      "Đang mở: SHEL.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/SHEL.csv\n",
      "Đang mở: SHW.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/SHW.csv\n",
      "Đang mở: SO.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/SO.csv\n",
      "Đang mở: TM.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/TM.csv\n",
      "Đang mở: TSLA.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/TSLA.csv\n",
      "Đang mở: TSM.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/TSM.csv\n",
      "Đang mở: TTE.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/TTE.csv\n",
      "Đang mở: UNH.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/UNH.csv\n",
      "Đang mở: UNP.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/UNP.csv\n",
      "Đang mở: UPS.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/UPS.csv\n",
      "Đang mở: V.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/V.csv\n",
      "Đang mở: VALE.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/VALE.csv\n",
      "Đang mở: VZ.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/VZ.csv\n",
      "Đang mở: WMT.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/WMT.csv\n",
      "Đang mở: XOM.csv\n",
      "Đã lưu: data/sample_price/technical_indicator/XOM.csv\n"
     ]
    }
   ],
   "source": [
    "## Tính Chỉ Báo Kỹ Thuật\n",
    "\n",
    "\n",
    "def calculate_technical_indicators(data):\n",
    "    \"\"\"\n",
    "    Tính toán các chỉ số kỹ thuật phổ biến cho dữ liệu chứng khoán.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame chứa dữ liệu chứng khoán (Open, High, Low, Close, Volume).\n",
    "                                 Yêu cầu các cột 'Open', 'High', 'Low', 'Close', 'Volume'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame chứa dữ liệu gốc và các chỉ số kỹ thuật.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Moving Averages\n",
    "    data['SMA_5'] = ta.sma(data['Close'], length=5)\n",
    "    data['EMA_5'] = ta.ema(data['Close'], length=5)\n",
    "\n",
    "    # 2. MACD\n",
    "    macd = ta.macd(data['Close'], fast=12, slow=26, signal=9)\n",
    "    data['MACD'] = macd['MACD_12_26_9']  # Lấy đường MACD\n",
    "    data['MACD_SIGNAL'] = macd['MACDs_12_26_9']  # Lấy đường tín hiệu\n",
    "    data['MACD_HIST'] = macd['MACDh_12_26_9']  # Lấy histogram\n",
    "\n",
    "    # 3. RSI\n",
    "    data['RSI'] = ta.rsi(data['Close'], length=5)\n",
    "\n",
    "    # 4. Bollinger Bands\n",
    "    bbands = ta.bbands(data['Close'], length=20, std=2)\n",
    "    data['BB_UPPER'] = bbands['BBU_20_2.0']\n",
    "    data['BB_LOWER'] = bbands['BBL_20_2.0']\n",
    "    data['BB_MIDDLE'] = bbands['BBM_20_2.0']\n",
    "\n",
    "    # 5. Volume Indicators (OBV)\n",
    "    data['OBV'] = ta.obv(data['Close'], data['Volume'])\n",
    "\n",
    "    # 6. ADX\n",
    "    adx = ta.adx(data['High'], data['Low'], data['Close'], length=14)\n",
    "    data['ADX'] = adx['ADX_14']\n",
    "    data['DMP'] = adx['DMP_14']  # Positive Directional Movement\n",
    "    data['DMN'] = adx['DMN_14']  # Negative Directional Movement\n",
    "\n",
    "    data = data.drop(columns = [\"Open\",\"High\",\"Low\",\"Close\", \"Adj Close\",\"Volume\"]) \n",
    "    return data.round(2)\n",
    "\n",
    "\n",
    "folder_path = 'data/sample_price/raw/'\n",
    "technical_indicator_folder = 'data/sample_price/technical_indicator/'  # Thư mục lưu file sau khi xử lý\n",
    "# Tạo thư mục technical_indicator_folder nếu chưa có\n",
    "os.makedirs(technical_indicator_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Kiểm tra thư mục có tồn tại không\n",
    "if os.path.exists(folder_path):\n",
    "    # Duyệt qua từng file trong thư mục\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        technical_indicator_path = os.path.join(technical_indicator_folder, file)  # Đường dẫn file mới\n",
    "\n",
    "        # Kiểm tra nếu file là CSV\n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Đang mở: {file}\")\n",
    "\n",
    "            # Đọc file CSV vào DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            # print(df.head())  # In 5 dòng đầu của file\n",
    "\n",
    "            df = calculate_technical_indicators(df)\n",
    "\n",
    "            # Ghi file vào thư mục processed\n",
    "            df.to_csv(technical_indicator_path, index=False)\n",
    "            print(f\"Đã lưu: {technical_indicator_path}\")\n",
    "        # break\n",
    "else:\n",
    "    print(\"Thư mục không tồn tại.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "Args in experiment:\n",
      "Loading Train Agents...\n",
      "AMZN = ticker, tweet_data =  ['RT @IBDinvestors: $AMZN \"With this... we had to back away yesterday bc it broke our expectations by falling below the 50-day. Don\\'t get dis…', 'RT @DeItaOne: $AMZN BANS N95, SURGICAL MASK SALES TO GENERAL PUBLIC: RECODE', \"And that's bullish, GTFOH $ES $ES_F $SPX $SPY $QQQ $IWM $VXX $VIX $AAPL $AMZN $MSFT https://t.co/TnRBO8RfWm\", 'RT @DeItaOne: AMAZON SAYS IT HAS FILLED 80,000 OF THE 100,000 JOBS IT ANNOUNCED LAST MONTH\\n$AMZN', 'BOOM 💰💰 Come Join US \\n$fb $aapl $amzn $nflx $googl $bidu $roku $spy $amd $nvda $tsla $ba $baba $shop For  Daily Powerful Watchlist, Swing &amp; Day Option Trading Alerts  Paypal monthly link in bio, $149.99 DM for biweekly link $84.99 #trading #optionstrader #Money https://t.co/eULM8jNbkw', 'RT @arnabch01: @FriseSally @Marinella_Maria @MariangelaSant8 @sminaev2015 @angelicagallegs @YukariKingdom18 @mhall55nine @eoff_sylvia @Mont…', \"RT @OphirGottlieb: $AMZN $AAPL You can finally buy Amazon Prime shows and movies in-app on Apple devices, after Amazon bypasses Apple's 30%…\", 'RT @aaaamhim: $NSPX OVERSOLD #BIOTECH with cancer PATENT. $1 runner?💸📈 #STOCKS #blockchain #Crypto #bitcoin #XRP #ico #startup $TWTR $DWDP…', 'Market Risk Elevated: Using Smarter Stop-Losses to Protect Yourself https://t.co/r5b29AI3wT $SPY $QQQ $DJIA $DIA #stockmarket #investing #finance #stocks #gold #silver $SLV $TWTR $GLD $FB $TLT $AAPL $TSLA $AMZN $NFLX $AMD $INTC #economy \\n@SmartStops', '$SPY $MSFT $AMZN $FB $SBUX $JPM $CMG $JNJ $BABA $NKE $CCL $UNH $NVDA $DIS $VZ $TSLA $QQQ $MSI $WMT $NOW $NFLX $DECK $MELI $BKNG $PLNT $BA $CCL $WYNN $RCL $AAL $OXY $XOM https://t.co/2lY1bp5LRq', 'Lawmakers, unions heap more pressure on Amazon $AMZN #coronavirus #COVID2019 https://t.co/BBOMfVd6hf', 'RT @DeItaOne: AMAZON SAYS IT WILL ROLL OUT MASKS, TEMPERATURE CHECKS FOR U.S. AND EUROPEAN STAFF BY NEXT WEEK\\n$AMZN', \"RT @caetuscap: *JEFF BEZOS GIVES $100M GIFT TO FEEDING AMERICA  $AMZN\\n\\nthat's more like it 🇺🇸\", 'RT @garrytan: Peter Thiel grilling Eric Schmidt (2012)\\n\\n🏭 Google isn’t a tech co anymore\\n🏦 It’s a tech holding co with $50B in cash and no…', 'RT @TheStreet: Amazon $AMZN will roll out temperature checks and face masks for staff at all its U.S. and European warehouses and Whole Foo…', 'RT @LiveSquawk: #COVID19 $AMZN | Amazon Is Banning The Sale Of N95 And Surgical Masks To The General Public - ReCode\\nhttps://t.co/2efJDdDC2B', \"$AMZN has filled 80,000 jobs in the span of a few weeks, part of a hiring spree to add 100,000 workers to meet soaring demand in the wake of the coronavirus pandemic. The only ones that will be left standing $COST $WMT and I'm adding $TGT\", 'CIOs expect lower PC, higher security spending - Instinet https://t.co/Qid0aY6pme $AMZN, $MSFT, $INTC, $AMD, $NVDA, $DELL, $CSCO, $HPE Great Dividend Stock BUY INTC!', 'RT @HedgeMind: During 2008 financial crisis from high to low:\\n$AMZN   -55% \\n$AAPL     -55%\\n$MSFT     -60%\\n$GOOGL -63% \\n...\\n\\nOf course then,…', 'RT @11Graphs: ★☆ Largest U.S. #Stocks ☆★\\n\\n(5/9)\\nBest performing by 52-Weeks Stock Return:\\n1. 🇺🇸 NVIDIA $NVDA: +39.8%\\n2. 🇺🇸 MICROSOFT $MSFT:…', 'RT @the_chart_life: Man, looking back at some of these charts from just 6-7 weeks ago, all you can do is laugh. I remember $AMZN breaking o…', 'RT @carlquintanilla: Amazon is partnering with #SXSW2020 to host an on-line festival. Filmmakers who had been scheduled to screen films in…', '$CDEV premarket gift Hedgefunds LOADING💸📈 $AAPL $AMD $AMRN $AAL $BAC $AMZN $MSFT $BA $ABT $TSLA $X $NVDA $GE $DIS $CCL $UBER $DAL $NFLX $FB $T $F $MU $SQ $M $ZM $XOM $GILD $ROKU $UAL $JPM $ABBV $FCX $SNAP $BABA $WFC $RCL $BB $HSBC $LYG $TEVA $C $OXY $JNJ $LYFT $LK $SBUX $BA $M https://t.co/UFtiGgmsSP', '*AMAZON BANS N95, SURGICAL MASK SALES TO GENERAL PUBLIC: RECODE  $AMZN', 'RT @SusanLiTV: ‘He’s Not Smart or Articulate’ \\n\\n#ViceNews obtaining internal #Amazon memo proposing to smear #AmazonStrike leader $amzn', \"RT @realwillmeade: This Bezos story tonight is incredible \\nI mean is Amazon $AMZN literally just the world's largest sweat shop.\"]\n",
      "tweets len =  26\n",
      "tweets len =  4\n",
      "BABA = ticker, tweet_data =  [\"As I've said many times, no one has any idea what is going on with Chinese businesses. There is NO transparency. No one has any clue.  Here is a coffee chain that was flubbing the numbers. What are the big guys like $TCEHY $BABA $JD $YY doing? $LK\", '$CDEV premarket gift Hedgefunds LOADING💸📈 $AAPL $AMD $AMRN $AAL $BAC $AMZN $MSFT $BA $ABT $TSLA $X $NVDA $GE $DIS $CCL $UBER $DAL $NFLX $FB $T $F $MU $SQ $M $ZM $XOM $GILD $ROKU $UAL $JPM $ABBV $FCX $SNAP $BABA $WFC $RCL $BB $HSBC $LYG $TEVA $C $OXY $JNJ $LYFT $LK $SBUX $BA $M https://t.co/UFtiGgmsSP', '@APompliano @ErnestMEdsel1 $SPY $MSFT $AMZN $FB $SBUX $JPM $CMG $JNJ $BABA $NKE $CCL $UNH $NVDA $DIS $VZ $TSLA $QQQ $MSI $WMT $NOW $NFLX $DECK $MELI $BKNG $PLNT $BA $CCL $WYNN $RCL $AAL', 'RT @UPBOptionMil: Some of todays top stock option open interest changes 4.2.20 $AAL $GM $X $FCX $BABA $GOLD $CCL $TEVA $MAS https://t.co/4K…']\n",
      "tweets len =  4\n",
      "tweets len =  4\n",
      "  ticker                                            summary    target  \\\n",
      "0   AMZN  2020-04-02\\nAmazon (AMZN) recently banned the ...  Positive   \n",
      "\n",
      "        date  \n",
      "0 2020-04-07  \n",
      "DataFrame đã được lưu vào 'data.csv'\n"
     ]
    }
   ],
   "source": [
    "%run testmain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung tệp CSV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>summary</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>technical_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-04-02\\nAmazon (AMZN) banned N95 and surgi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>SMA_5: 97.42\\nEMA_5: 98.33\\nMACD: 0.73\\nMACD_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-04-15\\nThe Pentagon awarded a $10 billion...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>SMA_5: 115.43\\nEMA_5: 115.08\\nMACD: 5.54\\nMACD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                                            summary    target  \\\n",
       "0   AMZN  2020-04-02\\nAmazon (AMZN) banned N95 and surgi...  Positive   \n",
       "1   AMZN  2020-04-15\\nThe Pentagon awarded a $10 billion...  Negative   \n",
       "\n",
       "         date                                technical_indicator  \n",
       "0  2020-04-07  SMA_5: 97.42\\nEMA_5: 98.33\\nMACD: 0.73\\nMACD_S...  \n",
       "1  2020-04-17  SMA_5: 115.43\\nEMA_5: 115.08\\nMACD: 5.54\\nMACD...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Đọc tệp CSV\n",
    "df_loaded = pd.read_csv(\"data_sample2.csv\")\n",
    "\n",
    "# Hiển thị nội dung DataFrame\n",
    "print(\"Nội dung tệp CSV:\")\n",
    "# print(df_loaded)\n",
    "df_loaded['summary']\n",
    "df_loaded = df_loaded[:2]\n",
    "df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train Agents.\n",
      "self.target, self.prediction Positive  ///////// \n",
      "self.is_finished() =  False       not self.is_correct() =  True\n",
      "Facts:\n",
      "2020-04-02\n",
      "Amazon (AMZN) banned N95 and surgical mask sales to the general public due to supply shortages caused by the COVID-19 pandemic. Additionally, Amazon announced that it has filled 80,000 out of the 100,000 jobs it announced last month.\n",
      "\n",
      "2020-04-05\n",
      "The tweets are not relevant or specific to the AMZN (Amazon) stock.\n",
      "\n",
      "Technical Indicators:\n",
      "SMA_5: 97.42\n",
      "EMA_5: 98.33\n",
      "MACD: 0.73\n",
      "MACD_SIGNAL: -0.1\n",
      "MACD_HIST: 0.83\n",
      "RSI: 70.53\n",
      "BB_UPPER: 102.76\n",
      "BB_LOWER: 85.13\n",
      "BB_MIDDLE: 93.94\n",
      "OBV: 396,412,000.0\n",
      "ADX: 15.59\n",
      "DMP: 27.43\n",
      "DMN: 17.77\n",
      "\n",
      "Price Movement: Positive  \n",
      "Explanation: Amazon reported significant supply chain challenges affecting N95 and surgical mask availability due to COVID-19, which could impact demand but was offset by news of job fillings. The strong upward trend indicated by the technical indicators—MACD above the signal line with positive history, moderate RSI, and ADX indicating a bullish trend—suggests that despite short-term challenges, the stock is expected to rise.\n",
      "\n",
      "\n",
      "\n",
      "self.target, self.prediction Positive  ///////// Positive\n",
      "self.target, self.prediction Negative  ///////// \n",
      "self.is_finished() =  False       not self.is_correct() =  True\n",
      "Facts:\n",
      "2020-04-15\n",
      "The Pentagon awarded a $10 billion Jedi contract to Microsoft over Amazon.\n",
      "Amazon's stock price reached a new all-time high due to unprecedented demand during the coronavirus pandemic.\n",
      "\n",
      "Technical Indicators:\n",
      "SMA_5: 115.43\n",
      "EMA_5: 115.08\n",
      "MACD: 5.54\n",
      "MACD_SIGNAL: 3.01\n",
      "MACD_HIST: 2.52\n",
      "RSI: 84.24\n",
      "BB_UPPER: 118.79\n",
      "BB_LOWER: 84.78\n",
      "BB_MIDDLE: 101.79\n",
      "OBV: 898,602,000.0\n",
      "ADX: 29.2\n",
      "DMP: 44.12\n",
      "DMN: 10.91\n",
      "\n",
      "Price Movement: (1) Positive  \n",
      "The price movement for AMZN stock is expected to be Positive.  \n",
      "\n",
      "(2) **Explanation:**  \n",
      "On 2020-04-15, Amazon faced a potential competition from Microsoft in a $10 billion Jedi contract, which might have implications despite Amazon's strong position in other sectors. However, during the COVID-19 pandemic, Amazon's stock reached a new all-time high due to increased demand for e-commerce services, highlighting its resilience and growth potential. Technical indicators such as a bullish MACD, overbought RSI (84.24), positive On-Balancing Volume (OBV: 898 million), and strong ADX (29.2) suggest ongoing bullish momentum. The stock is currently near the BB_MIDDLE with room for further gains toward BB_UPPER at 118.79, indicating sustained strength in the short term.\n",
      "\n",
      "\n",
      "\n",
      "self.target, self.prediction Negative  ///////// (1)\n",
      "aslmjdlasmdl\n",
      "self.target, self.prediction Positive  ///////// Positive\n",
      "self.target, self.prediction Negative  ///////// (1)\n",
      "self.target, self.prediction Positive  ///////// Positive\n",
      "self.target, self.prediction Negative  ///////// (1)\n",
      "Finished Trial 0, Correct: 1, Incorrect: 1\n"
     ]
    }
   ],
   "source": [
    "from explain_module.util import summarize_trial, remove_reflections, save_results#, save_agents\n",
    "from explain_module.agents import PredictReflectAgent\n",
    "\n",
    "import os, json\n",
    "\n",
    "agent_cls = PredictReflectAgent\n",
    "agents = [agent_cls(row['ticker'], row['summary'], row['target'], row['technical_indicator']) for _, row in df_loaded.iterrows()]\n",
    "print(\"Loaded Train Agents.\")\n",
    "agents\n",
    "\n",
    "for agent in agents:\n",
    "    agent.run()\n",
    "    # break\n",
    "\n",
    "    if agent.is_correct():\n",
    "        prompt = agent._build_agent_prompt()\n",
    "        response = agent.scratchpad.split('Price Movement: ')[-1]\n",
    "        sample = {\"instruction\": prompt, \"input\": \"\", \"output\": response}\n",
    "\n",
    "print(\"aslmjdlasmdl\")\n",
    "correct, incorrect = summarize_trial(agents)\n",
    "print(f'Finished Trial 0, Correct: {len(correct)}, Incorrect: {len(incorrect)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Nội dung tệp CSV:\n",
      "Loaded Train Agents.\n",
      "Facts:\n",
      "2020-04-02\n",
      "Amazon (AMZN) recently banned the sale of N95 and surgical masks to the general public. \n",
      "Amazon has already filled 80,000 of the 100,000 jobs it announced last month.\n",
      "\n",
      "Price Movement: "
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2370dceeaf0 state=finished raised OpenAIError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tenacity\\__init__.py:470\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[1;32me:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\utils\\llm.py:32\u001b[0m, in \u001b[0;36mOpenAILLM.__call__\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     31\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m---> 32\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[0;32m     33\u001b[0m response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\openai\\_utils\\_proxy.py:20\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 20\u001b[0m     proxied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_proxied__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxied, LazyProxy):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\openai\\_utils\\_proxy.py:55\u001b[0m, in \u001b[0;36mLazyProxy.__get_proxied__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_proxied__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\openai\\_module_client.py:12\u001b[0m, in \u001b[0;36mChatProxy.__load__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__load__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m resources\u001b[38;5;241m.\u001b[39mChat:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchat\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\openai\\__init__.py:323\u001b[0m, in \u001b[0;36m_load_client\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _client\n\u001b[1;32m--> 323\u001b[0m _client \u001b[38;5;241m=\u001b[39m \u001b[43m_ModuleClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _client\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\openai\\_client.py:104\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mE:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\test_explain.py:97\u001b[0m\n\u001b[0;32m     94\u001b[0m agents\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[1;32m---> 97\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mis_correct():\n\u001b[0;32m    100\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39m_build_agent_prompt()\n",
      "File \u001b[1;32me:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\explain_module\\agents.py:82\u001b[0m, in \u001b[0;36mPredictReflectAgent.run\u001b[1;34m(self, reset)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_correct():\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreflect()\n\u001b[1;32m---> 82\u001b[0m \u001b[43mPredictAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\explain_module\\agents.py:34\u001b[0m, in \u001b[0;36mPredictAgent.run\u001b[1;34m(self, reset)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscratchpad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m facts\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(facts, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscratchpad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscratchpad\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice Movement: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32me:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\explain_module\\agents.py:42\u001b[0m, in \u001b[0;36mPredictAgent.prompt_agent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_agent_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tenacity\\__init__.py:330\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\n\u001b[0;32m    327\u001b[0m     f, functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    328\u001b[0m )\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tenacity\\__init__.py:467\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tenacity\\__init__.py:368\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tenacity\\__init__.py:411\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x2370dceeaf0 state=finished raised OpenAIError>]"
     ]
    }
   ],
   "source": [
    "%run test_explain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a list of facts, estimate their overall impact on the price movement of AMZN stock. Give your response in this format:\n",
      "(1) Price Movement, which should be either Positive or Negative.\n",
      "(2) Explanation, which should be in a single, short paragraph.\n",
      "Here are some examples:\n",
      "Facts:\n",
      "2016-07-26\n",
      "Apple reported Q3 2016 earnings: Revenue of $42.4 billion, beating expectations. They sold 40.4 million iPhones, 9.9 million iPads, and 4.2 million Macs during that quarter.\n",
      "Apple's earnings beat expectations, causing the stock to rise by almost 5% in after-hours trading.\n",
      "Apple had $231.5 billion in cash reserves, enough to potentially acquire companies like Uber, Tesla, Twitter, Airbnb, Netflix, Snapchat, and SpaceX and still have billions left.\n",
      "Apple's China sales were down around 29% sequentially and 33% YoY.\n",
      "Despite declining unit sales, Apple's revenue was boosted by more expensive iPad Pro models.\n",
      "Apple Pay accounted for 3/4 of contactless payments in the US.\n",
      "Apple's services business (App Store, Apple Music, etc.) was projected to be the size of a Fortune 500 company in the next year.\n",
      "Apple was reported to be working on a car project called Project Titan, with Bob Mansfield leading it.\n",
      "The Apple Pencil was granted a patent to work with a Mac's trackpad.\n",
      "Apple faced declining iPhone sales, but the company focused on promoting apps and services.\n",
      "The stock price experienced fluctuations after the earnings report, with significant after-hours gains.\n",
      "Apple's market weight rating was reiterated by Wells Fargo, with a target price of $120.00.\n",
      "\n",
      "Price Movement: Positive\n",
      "\n",
      "Explanation: Apple reported strong Q3 2016 earnings, surpassing revenue expectations and delivering robust sales figures across its product lines, including iPhones, iPads, and Macs. This performance exceeded market projections and triggered a nearly 5% increase in the stock's after-hours trading. Additionally, Apple's substantial cash reserves of $231.5 billion, capable of facilitating major acquisitions, demonstrated the company's financial stability and growth potential. Despite challenges in China, Apple's diverse revenue sources, including higher-priced iPad Pro models and the dominant Apple Pay in US contactless payments, contributed positively to its overall Price Movement. The promising growth trajectory of Apple's services business added further optimism. While facing declining iPhone sales, Apple's strategic focus on promoting apps and services reflected adaptability in response to changing market dynamics. The consistent support from Wells Fargo with a reiterated market weight rating and target price also reinforced investor confidence. The stock's fluctuations were notable but aligned with the positive earnings report, showcasing the market's responsiveness to Apple's performance.\n",
      "\n",
      "Facts:\n",
      "2016-04-26\n",
      "Apple reported its Q2 2016 earnings, missing both profit and revenue estimates.\n",
      "Apple's revenue for the quarter was $50.56 billion, falling short of the estimated $52 billion.\n",
      "The company's adjusted earnings per share (EPS) was $1.90, lower than the expected $2.00.\n",
      "This marks the first time in 13 years that Apple experienced a quarterly decline in revenue.\n",
      "iPhone sales experienced a decline for the first time since its debut in 2007.\n",
      "The company's guidance for the next quarter indicates expected sales of $41 billion to $43 billion.\n",
      "Apple's dividend yield increased to 2.3%.\n",
      "CEO Tim Cook attributed the challenges to strong macroeconomic headwinds, especially in China.\n",
      "Despite the earnings miss, Apple announced plans to raise its dividend and return $50 billion more to shareholders.\n",
      "Apple's stock price experienced a decline of around 4.8% in after-hours trading following the earnings report.\n",
      "\n",
      "Price Movement: Negative\n",
      "\n",
      "Explanation: Apple reported disappointing Q2 2016 earnings, missing both profit and revenue estimates. The company's revenue and adjusted earnings per share fell short of expectations, marking the first quarterly revenue decline in 13 years. iPhone sales, a cornerstone of Apple's business, experienced their first-ever decline since the product's debut in 2007. The weaker-than-expected guidance for the next quarter further dampened investor Price Movement. The CEO's acknowledgment of strong macroeconomic headwinds, particularly in China, indicated external challenges affecting the company's performance. Despite announcing plans to increase dividends and return more to shareholders, the stock price plunged around 4.8% in after-hours trading following the earnings report. Overall, these factors collectively indicate a negative Price Movement surrounding AAPL stock due to its underwhelming financial performance and market outlook.\n",
      "\n",
      "(END OF EXAMPLES)\n",
      "\n",
      "\n",
      "\n",
      "Facts:\n",
      "2020-04-02\n",
      "Amazon (AMZN) recently banned the sale of N95 and surgical masks to the general public. \n",
      "Amazon has already filled 80,000 of the 100,000 jobs it announced last month.\n",
      "\n",
      "Price Movement:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/merge_sample.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# print(data)  # Output: [{'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 30}]\n",
    "print(data[4]['instruction'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'user_input': \"Given a list of facts, estimate their overall impact on the price movement of AMZN stock. Give your response in this format:\\n(1) Price Movement, which should be either Positive or Negative.\\n(2) Explanation, which should be in a single, short paragraph.\\nHere are some examples:\\nFacts:\\n2016-07-26\\nApple reported Q3 2016 earnings: Revenue of $42.4 billion, beating expectations. They sold 40.4 million iPhones, 9.9 million iPads, and 4.2 million Macs during that quarter.\\nApple's earnings beat expectations, causing the stock to rise by almost 5% in after-hours trading.\\nApple had $231.5 billion in cash reserves, enough to potentially acquire companies like Uber, Tesla, Twitter, Airbnb, Netflix, Snapchat, and SpaceX and still have billions left.\\nApple's China sales were down around 29% sequentially and 33% YoY.\\nDespite declining unit sales, Apple's revenue was boosted by more expensive iPad Pro models.\\nApple Pay accounted for 3/4 of contactless payments in the US.\\nApple's services business (App Store, Apple Music, etc.) was projected to be the size of a Fortune 500 company in the next year.\\nApple was reported to be working on a car project called Project Titan, with Bob Mansfield leading it.\\nThe Apple Pencil was granted a patent to work with a Mac's trackpad.\\nApple faced declining iPhone sales, but the company focused on promoting apps and services.\\nThe stock price experienced fluctuations after the earnings report, with significant after-hours gains.\\nApple's market weight rating was reiterated by Wells Fargo, with a target price of $120.00.\\n\\nPrice Movement: Positive\\n\\nExplanation: Apple reported strong Q3 2016 earnings, surpassing revenue expectations and delivering robust sales figures across its product lines, including iPhones, iPads, and Macs. This performance exceeded market projections and triggered a nearly 5% increase in the stock's after-hours trading. Additionally, Apple's substantial cash reserves of $231.5 billion, capable of facilitating major acquisitions, demonstrated the company's financial stability and growth potential. Despite challenges in China, Apple's diverse revenue sources, including higher-priced iPad Pro models and the dominant Apple Pay in US contactless payments, contributed positively to its overall Price Movement. The promising growth trajectory of Apple's services business added further optimism. While facing declining iPhone sales, Apple's strategic focus on promoting apps and services reflected adaptability in response to changing market dynamics. The consistent support from Wells Fargo with a reiterated market weight rating and target price also reinforced investor confidence. The stock's fluctuations were notable but aligned with the positive earnings report, showcasing the market's responsiveness to Apple's performance.\\n\\nFacts:\\n2016-04-26\\nApple reported its Q2 2016 earnings, missing both profit and revenue estimates.\\nApple's revenue for the quarter was $50.56 billion, falling short of the estimated $52 billion.\\nThe company's adjusted earnings per share (EPS) was $1.90, lower than the expected $2.00.\\nThis marks the first time in 13 years that Apple experienced a quarterly decline in revenue.\\niPhone sales experienced a decline for the first time since its debut in 2007.\\nThe company's guidance for the next quarter indicates expected sales of $41 billion to $43 billion.\\nApple's dividend yield increased to 2.3%.\\nCEO Tim Cook attributed the challenges to strong macroeconomic headwinds, especially in China.\\nDespite the earnings miss, Apple announced plans to raise its dividend and return $50 billion more to shareholders.\\nApple's stock price experienced a decline of around 4.8% in after-hours trading following the earnings report.\\n\\nPrice Movement: Negative\\n\\nExplanation: Apple reported disappointing Q2 2016 earnings, missing both profit and revenue estimates. The company's revenue and adjusted earnings per share fell short of expectations, marking the first quarterly revenue decline in 13 years. iPhone sales, a cornerstone of Apple's business, experienced their first-ever decline since the product's debut in 2007. The weaker-than-expected guidance for the next quarter further dampened investor Price Movement. The CEO's acknowledgment of strong macroeconomic headwinds, particularly in China, indicated external challenges affecting the company's performance. Despite announcing plans to increase dividends and return more to shareholders, the stock price plunged around 4.8% in after-hours trading following the earnings report. Overall, these factors collectively indicate a negative Price Movement surrounding AAPL stock due to its underwhelming financial performance and market outlook.\\n\\n(END OF EXAMPLES)\\n\\nFacts2020-04-17\\nAmazon is one of the five largest stocks in the S&P500.\\nThere is a large accumulation of volume in Amazon's stock.\\nAmazon's stock experienced extreme greed in February and extreme fear in March.\\n\\n2020-04-18\\nJeff Bezos' annual shareholder letter is recommended reading for investors.\\nThe S&P500 is now more concentrated in the 5 largest stocks, including Microsoft, Apple, Facebook, Google, and Amazon (AMZN), than ever before.\\nTech giants like Microsoft, Apple, Google, and Amazon faced significant declines in returns during the 2008 financial crisis.\\nIn 2020, Microsoft's returns were up 14%, while Apple's returns were down 3%.\\nAs of now, Microsoft has a market cap of $1.36 trillion, Apple has a market cap of $1.24 trillion, and Amazon has a market cap of an unknown amount.\\n\\nPrice Movement:\",\n",
       "   'completion_a': \"Neutral\\n\\nExplanation: The facts provided do not provide a clear indication of the overall impact on the price movement of AMZN stock. While Amazon being one of the five largest stocks in the S&P500 suggests a potentially positive influence, the accumulation of volume and extreme greed followed by extreme fear may suggest volatility and potential negative impact. The concentration of the S&P500 in the five largest stocks, including Amazon, could be seen as both positive and negative, depending on market conditions. The information about the returns of Microsoft and Apple provides further context but does not directly relate to Amazon's price movement. The lack of specific information about Amazon's market cap makes it difficult to assess its impact on price movement. Overall, the provided facts do not indicate a clear positive or negative Price Movement for AMZN stock.\",\n",
       "   'completion_b': \"Positive\\n\\nExplanation: The fact that Amazon is one of the five largest stocks in the S&P500 indicates its significant influence on the overall market and suggests a positive price movement. The large accumulation of volume in Amazon's stock further supports this notion, as it implies strong investor interest and potential buying pressure. Additionally, the extreme greed in February and extreme fear in March experienced by Amazon's stock indicates significant market fluctuations, which could lead to higher price volatility but ultimately result in a positive price movement. The suggestion that Jeff Bezos' annual shareholder letter is recommended reading for investors highlights the influential nature of his leadership and strategic insights, potentially impacting investor sentiment towards the stock. Furthermore, the increasing concentration of the S&P500 in the five largest stocks, including Amazon, suggests a market preference for these tech giants, which can positively impact their price movement. Lastly, the fact that Microsoft's returns were up 14% in 2020 while Apple's returns were down 3%, coupled with Amazon's unknown market cap, suggests the potential for Amazon to outperform its competitors and experience positive price movement.\"}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./datasets/comparison_data.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    datasets = [json.loads(line) for line in file]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 7\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "DATA_PATH ='./data/merge_sample.json'\n",
    "data = load_dataset(\"json\", data_files=DATA_PATH)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1 examples [00:00, 36.22 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'completion_a', 'completion_b'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"./datasets/\"\n",
    "train_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from lmsys/vicuna-7b-v1.5-16k on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--lmsys--vicuna-7b-v1.5-16k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards:   0%|          | 0/2 [03:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mE:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\test_predict.py:83\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredict_module\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupervised_finetune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supervised_finetune\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Train supervised policy\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[43msupervised_finetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m merge_peft_adapter(model_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_path, output_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mrl_base_model)\n",
      "File \u001b[1;32mE:\\Khóa Luận Tốt Nghiệp\\predicting stock  based on LLM\\office\\Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models\\sep-main\\predict_module\\supervised_finetune.py:41\u001b[0m, in \u001b[0;36msupervised_finetune\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on CPU...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensures model is on CPU\u001b[39;49;00m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(args\u001b[38;5;241m.\u001b[39mmodel_path, add_eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m prepare_model_for_int8_training(model)  \u001b[38;5;66;03m# Updated function\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\transformers\\modeling_utils.py:3944\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m   3943\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 3944\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3953\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3955\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3956\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3960\u001b[0m     is_safetensors_available()\n\u001b[0;32m   3961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   3962\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3963\u001b[0m ):\n\u001b[0;32m   3964\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\transformers\\utils\\hub.py:1098\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\file_download.py:1009\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1007\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1009\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[0;32m   1020\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\file_download.py:1543\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1540\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m   1541\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1552\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1553\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\huggingface_hub\\file_download.py:452\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    450\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    454\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\urllib3\\response.py:934\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 934\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    937\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\urllib3\\response.py:877\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 877\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\urllib3\\response.py:812\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    809\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 812\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\site-packages\\urllib3\\response.py:789\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    788\u001b[0m     chunk_amt \u001b[38;5;241m=\u001b[39m max_chunk_amt\n\u001b[1;32m--> 789\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_amt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\min_ds-env\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run test_predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "class DeepSeekLLM:\n",
    "    def __init__(self, model=\"deepseek-r1\"):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, prompt):\n",
    "        response = ollama.chat(model=self.model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        content = response[\"message\"][\"content\"]\n",
    "        \n",
    "        # Cắt từ vị trí của </think>\n",
    "        if \"</think>\" in content:\n",
    "            content = content.split(\"</think>\", 1)[-1].strip()\n",
    "        \n",
    "        return content\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "if __name__ == \"__main__\":\n",
    "    deepseek = DeepSeekLLM()\n",
    "    question = \"What is the capital of France?\"\n",
    "    answer = deepseek(question)\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "DeepSeek-R1-7B is a large language model that processes text in real-time, but the number of tokens it can generate or process in one go is limited only by the available system resources (such as memory and computational power). In practice, models like DeepSeek-R1-7B typically generate outputs in fixed-length chunks, often around 500-1000 tokens, depending on the specific configuration.\n",
      "\n",
      "If you're using a framework like the DeepSeek Engine or another platform that hosts DeepSeek-R1-7B, we recommend checking their documentation for specific details about token limits and usage policies. Always ensure you adhere to their guidelines to avoid any issues with your usage.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "desiredModel = 'deepseek-r1'\n",
    "# questionToAsk = 'How to solve a quadratic equation x^2+5*x+6=0'\n",
    "questionToAsk = ''' How many tokens can deepseek r1 7b receive each time?'''\n",
    "\n",
    "\n",
    "response = ollama.chat(model=desiredModel, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': questionToAsk,\n",
    "    },\n",
    "])\n",
    "\n",
    "OllamaResponse = response['message']['content']\n",
    "\n",
    "print(OllamaResponse)\n",
    "\n",
    "# with open(\"OutputOllama.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "#     text_file.write(OllamaResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
